{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQFvGnrbogmq",
        "outputId": "04b53327-a9e0-4007-eb17-a20879ebef5e"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# import zipfile\n",
        "# import os\n",
        "\n",
        "\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# zip_path = '/content/drive/MyDrive/apredizajeautomatico/QuickDraw-Animals.zip'  # Cambia esta ruta\n",
        "# zip_path_2 = '/content/drive/MyDrive/apredizajeautomatico/QuickDraw-10-Tarea2.zip'\n",
        "\n",
        "# extract_path = '/content/imagenes_descomprimidas'\n",
        "# os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_path)\n",
        "\n",
        "# with zipfile.ZipFile(zip_path_2, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_path)\n",
        "\n",
        "# print(f\"Archivos extraídos en: {extract_path}\")\n",
        "\n",
        "# print(\"Archivos extraídos:\")\n",
        "# print(os.listdir(extract_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_bnYsh3WtCDk"
      },
      "outputs": [],
      "source": [
        "# importacion de librerias\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ESQWEpOtIsJ"
      },
      "source": [
        "# Parte 1 - Lectura de Imágenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HycllJm_tKiG"
      },
      "outputs": [],
      "source": [
        "def load_image_paths_and_labels(file_path):\n",
        "    \"\"\"Carga las rutas de las imágenes y las etiquetas desde un archivo de texto.\"\"\"\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file.readlines():\n",
        "            path, label = line.strip().split('\\t')\n",
        "            image_paths.append(path)\n",
        "            labels.append(int(label))\n",
        "    return image_paths, np.array(labels)\n",
        "\n",
        "def load_images(image_paths, folder_route):\n",
        "    \"\"\"Carga las imágenes y las aplana a vectores.\"\"\"\n",
        "    images = []\n",
        "    for path in image_paths:\n",
        "        with Image.open(folder_route + path) as img:\n",
        "            img_array = np.array(img).reshape(-1)\n",
        "            images.append(img_array)\n",
        "    return np.array(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13v2Ol-ut_dJ"
      },
      "source": [
        "QuickDraw-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-dsSiI0ytMYW"
      },
      "outputs": [],
      "source": [
        "# # Cargar las rutas de entrenamiento y prueba junto con las etiquetas\n",
        "# train_image_paths_10, train_labels_10 = load_image_paths_and_labels(\"/content/imagenes_descomprimidas/QuickDraw-10/train.txt\")\n",
        "# test_image_paths_10, test_labels_10 = load_image_paths_and_labels(\"/content/imagenes_descomprimidas/QuickDraw-10/test.txt\")\n",
        "\n",
        "# # Cargar y procesar las imágenes\n",
        "# train_images_10 = load_images(train_image_paths_10, \"/content/imagenes_descomprimidas/QuickDraw-10/\")\n",
        "# test_images_10 = load_images(test_image_paths_10, \"/content/imagenes_descomprimidas/QuickDraw-10/\")\n",
        "\n",
        "\n",
        "# Cargar las rutas de entrenamiento y prueba junto con las etiquetas\n",
        "train_image_paths_10, train_labels_10 = load_image_paths_and_labels(\"./QuickDraw-10/train.txt\")\n",
        "test_image_paths_10, test_labels_10 = load_image_paths_and_labels(\"./QuickDraw-10/test.txt\")\n",
        "\n",
        "# Cargar y procesar las imágenes\n",
        "train_images_10 = load_images(train_image_paths_10, \"./QuickDraw-10/\")\n",
        "test_images_10 = load_images(test_image_paths_10, \"./QuickDraw-10/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lWI6a-Ddt7Wn"
      },
      "outputs": [],
      "source": [
        "# Preparacion datos de validacion\n",
        "train_images_10, val_image_10, train_labels_10, val_labels_10 = train_test_split(\n",
        "    train_images_10, train_labels_10, test_size=0.15, random_state=42, stratify=train_labels_10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yY1zYbFDHEbZ"
      },
      "outputs": [],
      "source": [
        "# normalizacion\n",
        "train_images_10 = train_images_10.astype('float32') / 255.0\n",
        "test_images_10 = test_images_10.astype('float32') / 255.0\n",
        "val_image_10 = val_image_10.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kQjCrgw8NJKO"
      },
      "outputs": [],
      "source": [
        "# one hot encoding\n",
        "n_classes=10\n",
        "train_labels_10 = to_categorical(train_labels_10, num_classes=n_classes)\n",
        "test_labels_10 = to_categorical(test_labels_10, num_classes=n_classes)\n",
        "val_labels_10 = to_categorical(val_labels_10, num_classes=n_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALUYnf1iuAMD"
      },
      "source": [
        "QuickDraw-Animals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wznfNYHnuClR"
      },
      "outputs": [],
      "source": [
        "def load_images_and_labels(dataset):\n",
        "    \"\"\"\n",
        "    Carga imágenes y etiquetas para train y test del dataset QuickDraw-Animals.\n",
        "\n",
        "    Retorna:\n",
        "      X_test, y_test, X_train, y_train (numpy arrays)\n",
        "    \"\"\"\n",
        "    if dataset != \"Animals\":\n",
        "        raise ValueError(\"Sólo soporta dataset 'Animals'.\")\n",
        "\n",
        "    # base_path = '/content/imagenes_descomprimidas/QuickDraw-Animals/'\n",
        "    base_path = './QuickDraw-Animals'\n",
        "    mapping_file = os.path.join(base_path, 'mapping.txt')\n",
        "\n",
        "    # Leer mapping.txt y crear diccionario etiqueta->número\n",
        "    label_map = {}\n",
        "    with open(mapping_file, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) == 2:\n",
        "                label = parts[0]\n",
        "                idx = int(parts[1])\n",
        "                label_map[label] = idx\n",
        "\n",
        "    def load_images_from_folder(folder_path):\n",
        "        images = []\n",
        "        labels = []\n",
        "        # Las subcarpetas son las clases\n",
        "        for label_name in sorted(os.listdir(folder_path)):\n",
        "            label_folder = os.path.join(folder_path, label_name)\n",
        "            if os.path.isdir(label_folder) and label_name in label_map:\n",
        "                for img_file in sorted(os.listdir(label_folder)):\n",
        "                    if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                        img_path = os.path.join(label_folder, img_file)\n",
        "                        with Image.open(img_path) as img:\n",
        "                            img_array = np.array(img).reshape(-1)\n",
        "                            images.append(img_array)\n",
        "                            labels.append(label_map[label_name])\n",
        "        return np.array(images), np.array(labels)\n",
        "\n",
        "    # Cargar test\n",
        "    # X_test, y_test = load_images_from_folder('/content/imagenes_descomprimidas/QuickDraw-Animals/test_images/test_images/')\n",
        "    X_test, y_test = load_images_from_folder('./QuickDraw-Animals/test_images/test_images')\n",
        "\n",
        "    # Cargar train\n",
        "    # X_train, y_train = load_images_from_folder('/content/imagenes_descomprimidas/QuickDraw-Animals/train_images/train_images/')\n",
        "    X_train, y_train = load_images_from_folder('./QuickDraw-Animals/train_images/train_images')\n",
        "\n",
        "\n",
        "    return X_test, y_test, X_train, y_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rGJkQEGNuLgQ"
      },
      "outputs": [],
      "source": [
        "test_images_animals, test_labels_animals, train_images_animals, train_labels_animals = load_images_and_labels(\"Animals\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I7OuAJoQuXNZ"
      },
      "outputs": [],
      "source": [
        "# Preparacion datos de validacion\n",
        "train_images_animals, val_images_animals, train_labels_animals, val_labels_animals = train_test_split(\n",
        "    train_images_animals, train_labels_animals, test_size=0.15, random_state=42, stratify=train_labels_animals\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_pZQys-EH0SE"
      },
      "outputs": [],
      "source": [
        "# normalizacion\n",
        "train_images_animals = train_images_animals.astype('float32') / 255.0\n",
        "test_images_animals = test_images_animals.astype('float32') / 255.0\n",
        "val_images_animals = val_images_animals.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "w5LhfPwPH-th"
      },
      "outputs": [],
      "source": [
        "# one hot encoding\n",
        "n_classes=12\n",
        "train_labels_animals = to_categorical(train_labels_animals, num_classes=n_classes)\n",
        "test_labels_animals = to_categorical(test_labels_animals, num_classes=n_classes)\n",
        "val_labels_animals = to_categorical(val_labels_animals, num_classes=n_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEtptvDwuZGK"
      },
      "source": [
        "## Parte 2 - Construcción de modelos\n",
        "\n",
        "Clase MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9-IjfB__ueYv"
      },
      "outputs": [],
      "source": [
        "class MLP(tf.keras.Model):\n",
        "    # defining components\n",
        "    def __init__(self, layers_size, n_classes, activation='sigmoid'):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer_list = []\n",
        "        for lsize in layers_size:\n",
        "            self.layer_list.append(tf.keras.layers.Dense(lsize))\n",
        "        self.classifier = tf.keras.layers.Dense(n_classes)\n",
        "        self.activation = activation\n",
        "\n",
        "\n",
        "    # defining architecture\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for mlp_layer in self.layer_list:\n",
        "            x = mlp_layer(x)\n",
        "            if self.activation == 'sigmoid':\n",
        "                x = tf.keras.activations.sigmoid(x)\n",
        "            elif self.activation == 'tanh':\n",
        "                x = tf.keras.activations.tanh(x)\n",
        "            else:\n",
        "                raise ValueError(\"Activación no soportada\")\n",
        "        x = self.classifier(x)\n",
        "        return tf.keras.activations.softmax(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA1PFhonukLZ"
      },
      "source": [
        "Funciones para entrenar, evaluar y realizar los experimentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Cr-CDYlmuk-6"
      },
      "outputs": [],
      "source": [
        "def train_model(model, X_train, y_train, X_val, y_val, loss_fn, epochs=10, batch_size=32):\n",
        "\n",
        "    # Entrenamiento\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.SGD(),\n",
        "        loss=loss_fn,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Detiene el proceso tras 5 epocas sin encontrar una mejora. Evalúa la pérdida en el\n",
        "    # conjunto de validación.\n",
        "    early_stopping = EarlyStopping(\n",
        "      monitor='val_loss',\n",
        "      patience=5,\n",
        "      restore_best_weights=True,\n",
        "      verbose=1\n",
        "    )\n",
        "\n",
        "    final_model = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "    return final_model\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, class_names):\n",
        "    y_pred_probs = model(X_test, training=False).numpy()\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # Si y_test es one-hot, convierte a etiquetas enteras\n",
        "    if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n",
        "        y_test_int = np.argmax(y_test, axis=1)\n",
        "    else:\n",
        "        y_test_int = y_test\n",
        "\n",
        "    acc_total = accuracy_score(y_test_int, y_pred)\n",
        "\n",
        "    acc_per_class = {}\n",
        "    for cls in np.unique(y_test_int):\n",
        "        idx = y_test_int == cls\n",
        "        acc = accuracy_score(y_test_int[idx], y_pred[idx])\n",
        "        acc_per_class[class_names[cls]] = acc\n",
        "\n",
        "    cm = confusion_matrix(y_test_int, y_pred)\n",
        "\n",
        "    return acc_total, acc_per_class, cm\n",
        "\n",
        "\n",
        "def experiment(X_train, y_train, X_val, y_val, X_test, y_test, layers_size, n_classes, activation, loss_fn, class_names, epochs=10, batch_size=None, n_experiments=5):\n",
        "    acc_totals = []\n",
        "    acc_classes_list = []\n",
        "    cm_list = []\n",
        "\n",
        "    for i in range(n_experiments):\n",
        "        print(f\"\\nEntrenamiento número {i+1}\")\n",
        "        # Crear modelo nuevo para reinicializar pesos\n",
        "        model = MLP(layers_size, n_classes, activation)\n",
        "        model.build(input_shape=(None, X_train.shape[1]))\n",
        "\n",
        "        # Entrenar\n",
        "        train_model(model, X_train, y_train, X_val, y_val, loss_fn, epochs, batch_size)\n",
        "\n",
        "        # Evaluar\n",
        "        acc_total, acc_per_class, cm = evaluate_model(model, X_test, y_test, class_names)\n",
        "        acc_totals.append(acc_total)\n",
        "        acc_classes_list.append(acc_per_class)\n",
        "        cm_list.append(cm)\n",
        "\n",
        "    return acc_totals, acc_classes_list, cm_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAOUMjhDBEN3"
      },
      "source": [
        "Experimentos para QuickDraw-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8ZQEHnrSBJMV"
      },
      "outputs": [],
      "source": [
        "clases = ['bandage', 'blackberry', 'castle', 'flashlight', 'lion', 'remote-control', 'sink', 'spreadsheet', 'teapot', 'trombone']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MJNUkmE4unJW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entrenamiento número 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 94ms/step - accuracy: 0.1378 - loss: 2.2980 - val_accuracy: 0.1050 - val_loss: 2.3555\n",
            "Epoch 2/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 89ms/step - accuracy: 0.2523 - loss: 2.1549 - val_accuracy: 0.1640 - val_loss: 2.2128\n",
            "Epoch 3/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 88ms/step - accuracy: 0.3477 - loss: 1.9828 - val_accuracy: 0.3293 - val_loss: 1.9319\n",
            "Epoch 4/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - accuracy: 0.4081 - loss: 1.8457 - val_accuracy: 0.4160 - val_loss: 1.8250\n",
            "Epoch 5/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 89ms/step - accuracy: 0.4476 - loss: 1.7295 - val_accuracy: 0.3381 - val_loss: 1.8729\n",
            "Epoch 6/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - accuracy: 0.4738 - loss: 1.6429 - val_accuracy: 0.4390 - val_loss: 1.6608\n",
            "Epoch 7/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - accuracy: 0.5083 - loss: 1.5519 - val_accuracy: 0.4173 - val_loss: 1.6708\n",
            "Epoch 8/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 88ms/step - accuracy: 0.5325 - loss: 1.4895 - val_accuracy: 0.3672 - val_loss: 1.6534\n",
            "Epoch 9/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - accuracy: 0.5279 - loss: 1.4721 - val_accuracy: 0.2995 - val_loss: 1.8802\n",
            "Epoch 10/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - accuracy: 0.5401 - loss: 1.4238 - val_accuracy: 0.5095 - val_loss: 1.4904\n",
            "Epoch 11/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - accuracy: 0.5585 - loss: 1.3614 - val_accuracy: 0.3604 - val_loss: 1.7756\n",
            "Epoch 12/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - accuracy: 0.5679 - loss: 1.3802 - val_accuracy: 0.2466 - val_loss: 2.0638\n",
            "Epoch 13/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - accuracy: 0.5776 - loss: 1.3332 - val_accuracy: 0.4451 - val_loss: 1.4900\n",
            "Epoch 14/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 88ms/step - accuracy: 0.5888 - loss: 1.2991 - val_accuracy: 0.5244 - val_loss: 1.4390\n",
            "Epoch 15/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - accuracy: 0.6007 - loss: 1.2523 - val_accuracy: 0.3713 - val_loss: 1.9121\n",
            "Epoch 16/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - accuracy: 0.6061 - loss: 1.2298 - val_accuracy: 0.4878 - val_loss: 1.6782\n",
            "Epoch 17/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - accuracy: 0.6131 - loss: 1.2260 - val_accuracy: 0.1186 - val_loss: 4.0168\n",
            "Epoch 18/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 462ms/step - accuracy: 0.6181 - loss: 1.2529 - val_accuracy: 0.4397 - val_loss: 1.6017\n",
            "Epoch 19/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 107ms/step - accuracy: 0.6166 - loss: 1.1851 - val_accuracy: 0.4966 - val_loss: 1.4267\n",
            "Epoch 20/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.6300 - loss: 1.1539 - val_accuracy: 0.4214 - val_loss: 1.7820\n",
            "Restoring model weights from the end of the best epoch: 19.\n",
            "\n",
            "Entrenamiento número 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 91ms/step - accuracy: 0.1280 - loss: 2.2984 - val_accuracy: 0.1179 - val_loss: 2.3066\n",
            "Epoch 2/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.2656 - loss: 2.1493 - val_accuracy: 0.1775 - val_loss: 2.1537\n",
            "Epoch 3/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.3514 - loss: 1.9839 - val_accuracy: 0.1829 - val_loss: 2.0590\n",
            "Epoch 4/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 93ms/step - accuracy: 0.4039 - loss: 1.8496 - val_accuracy: 0.3645 - val_loss: 1.8140\n",
            "Epoch 5/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.4549 - loss: 1.7250 - val_accuracy: 0.3625 - val_loss: 1.7653\n",
            "Epoch 6/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.4888 - loss: 1.6341 - val_accuracy: 0.3272 - val_loss: 1.8103\n",
            "Epoch 7/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.4856 - loss: 1.5765 - val_accuracy: 0.2900 - val_loss: 1.8826\n",
            "Epoch 8/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.5134 - loss: 1.5205 - val_accuracy: 0.3279 - val_loss: 1.8358\n",
            "Epoch 9/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 92ms/step - accuracy: 0.5373 - loss: 1.4552 - val_accuracy: 0.3117 - val_loss: 2.2302\n",
            "Epoch 10/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 95ms/step - accuracy: 0.5502 - loss: 1.4341 - val_accuracy: 0.4099 - val_loss: 1.6579\n",
            "Epoch 11/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 90ms/step - accuracy: 0.5784 - loss: 1.3612 - val_accuracy: 0.4797 - val_loss: 1.5246\n",
            "Epoch 12/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 93ms/step - accuracy: 0.5748 - loss: 1.3636 - val_accuracy: 0.4980 - val_loss: 1.4677\n",
            "Epoch 13/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.5787 - loss: 1.3172 - val_accuracy: 0.3123 - val_loss: 1.9527\n",
            "Epoch 14/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.5997 - loss: 1.2842 - val_accuracy: 0.5420 - val_loss: 1.3763\n",
            "Epoch 15/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 90ms/step - accuracy: 0.5909 - loss: 1.2794 - val_accuracy: 0.4397 - val_loss: 1.5972\n",
            "Epoch 16/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.6188 - loss: 1.2154 - val_accuracy: 0.2629 - val_loss: 2.1654\n",
            "Epoch 17/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.6027 - loss: 1.2313 - val_accuracy: 0.4004 - val_loss: 1.7510\n",
            "Epoch 18/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.6215 - loss: 1.2148 - val_accuracy: 0.4140 - val_loss: 1.6492\n",
            "Epoch 19/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.6399 - loss: 1.1733 - val_accuracy: 0.5095 - val_loss: 1.3874\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n",
            "\n",
            "Entrenamiento número 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 92ms/step - accuracy: 0.1247 - loss: 2.3057 - val_accuracy: 0.1436 - val_loss: 2.2702\n",
            "Epoch 2/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.2416 - loss: 2.1599 - val_accuracy: 0.1077 - val_loss: 2.1907\n",
            "Epoch 3/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.3402 - loss: 2.0028 - val_accuracy: 0.2331 - val_loss: 2.0548\n",
            "Epoch 4/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.4071 - loss: 1.8467 - val_accuracy: 0.2019 - val_loss: 2.2524\n",
            "Epoch 5/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 94ms/step - accuracy: 0.4462 - loss: 1.7454 - val_accuracy: 0.3178 - val_loss: 1.8869\n",
            "Epoch 6/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.4915 - loss: 1.6263 - val_accuracy: 0.3266 - val_loss: 1.9339\n",
            "Epoch 7/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.5023 - loss: 1.5636 - val_accuracy: 0.1524 - val_loss: 2.4045\n",
            "Epoch 8/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.5192 - loss: 1.5011 - val_accuracy: 0.2446 - val_loss: 2.0549\n",
            "Epoch 9/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.5433 - loss: 1.4460 - val_accuracy: 0.4641 - val_loss: 1.5524\n",
            "Epoch 10/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.5600 - loss: 1.3928 - val_accuracy: 0.4112 - val_loss: 1.7806\n",
            "Epoch 11/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.5682 - loss: 1.3547 - val_accuracy: 0.4553 - val_loss: 1.5619\n",
            "Epoch 12/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.5795 - loss: 1.3363 - val_accuracy: 0.4363 - val_loss: 1.6149\n",
            "Epoch 13/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.5917 - loss: 1.3088 - val_accuracy: 0.3943 - val_loss: 1.6927\n",
            "Epoch 14/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.5813 - loss: 1.3166 - val_accuracy: 0.4600 - val_loss: 1.6123\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\n",
            "Entrenamiento número 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 91ms/step - accuracy: 0.1260 - loss: 2.2998 - val_accuracy: 0.1084 - val_loss: 2.2468\n",
            "Epoch 2/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.2543 - loss: 2.1457 - val_accuracy: 0.2046 - val_loss: 2.1584\n",
            "Epoch 3/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.3562 - loss: 1.9834 - val_accuracy: 0.2358 - val_loss: 2.0731\n",
            "Epoch 4/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.4218 - loss: 1.8310 - val_accuracy: 0.1484 - val_loss: 2.2923\n",
            "Epoch 5/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.4509 - loss: 1.7226 - val_accuracy: 0.3299 - val_loss: 1.8037\n",
            "Epoch 6/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 94ms/step - accuracy: 0.4836 - loss: 1.6259 - val_accuracy: 0.2778 - val_loss: 1.8955\n",
            "Epoch 7/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.5177 - loss: 1.5298 - val_accuracy: 0.2446 - val_loss: 2.1233\n",
            "Epoch 8/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.5194 - loss: 1.5097 - val_accuracy: 0.2453 - val_loss: 2.0541\n",
            "Epoch 9/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.5352 - loss: 1.4472 - val_accuracy: 0.3713 - val_loss: 1.7554\n",
            "Epoch 10/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 99ms/step - accuracy: 0.5502 - loss: 1.4135 - val_accuracy: 0.2304 - val_loss: 2.3468\n",
            "Epoch 11/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 96ms/step - accuracy: 0.5505 - loss: 1.3936 - val_accuracy: 0.3963 - val_loss: 1.7040\n",
            "Epoch 12/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 94ms/step - accuracy: 0.5726 - loss: 1.3374 - val_accuracy: 0.4980 - val_loss: 1.4376\n",
            "Epoch 13/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.5821 - loss: 1.3137 - val_accuracy: 0.5427 - val_loss: 1.3931\n",
            "Epoch 14/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.6002 - loss: 1.2560 - val_accuracy: 0.4011 - val_loss: 1.7705\n",
            "Epoch 15/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.5901 - loss: 1.2889 - val_accuracy: 0.4309 - val_loss: 1.7069\n",
            "Epoch 16/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.6139 - loss: 1.2193 - val_accuracy: 0.4600 - val_loss: 1.5639\n",
            "Epoch 17/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 93ms/step - accuracy: 0.6126 - loss: 1.2321 - val_accuracy: 0.1640 - val_loss: 3.1564\n",
            "Epoch 18/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.6096 - loss: 1.2412 - val_accuracy: 0.5244 - val_loss: 1.3738\n",
            "Epoch 19/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.6308 - loss: 1.1681 - val_accuracy: 0.5285 - val_loss: 1.4629\n",
            "Epoch 20/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 93ms/step - accuracy: 0.6322 - loss: 1.1386 - val_accuracy: 0.4668 - val_loss: 1.6221\n",
            "Restoring model weights from the end of the best epoch: 18.\n",
            "\n",
            "Entrenamiento número 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 93ms/step - accuracy: 0.1289 - loss: 2.2945 - val_accuracy: 0.1165 - val_loss: 2.2345\n",
            "Epoch 2/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 93ms/step - accuracy: 0.2706 - loss: 2.1293 - val_accuracy: 0.1253 - val_loss: 2.2287\n",
            "Epoch 3/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 94ms/step - accuracy: 0.3475 - loss: 1.9739 - val_accuracy: 0.2636 - val_loss: 1.9328\n",
            "Epoch 4/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 93ms/step - accuracy: 0.4201 - loss: 1.8084 - val_accuracy: 0.3442 - val_loss: 1.8831\n",
            "Epoch 5/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.4549 - loss: 1.6826 - val_accuracy: 0.2771 - val_loss: 2.0043\n",
            "Epoch 6/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.4788 - loss: 1.6141 - val_accuracy: 0.1396 - val_loss: 2.5994\n",
            "Epoch 7/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.5146 - loss: 1.5372 - val_accuracy: 0.3408 - val_loss: 1.7942\n",
            "Epoch 8/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 95ms/step - accuracy: 0.5228 - loss: 1.4840 - val_accuracy: 0.3625 - val_loss: 1.9056\n",
            "Epoch 9/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 93ms/step - accuracy: 0.5463 - loss: 1.4393 - val_accuracy: 0.4356 - val_loss: 1.6560\n",
            "Epoch 10/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 94ms/step - accuracy: 0.5565 - loss: 1.3930 - val_accuracy: 0.4289 - val_loss: 1.5239\n",
            "Epoch 11/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 98ms/step - accuracy: 0.5620 - loss: 1.3657 - val_accuracy: 0.4119 - val_loss: 1.6702\n",
            "Epoch 12/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 93ms/step - accuracy: 0.5797 - loss: 1.3357 - val_accuracy: 0.2446 - val_loss: 2.0111\n",
            "Epoch 13/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 93ms/step - accuracy: 0.5783 - loss: 1.3238 - val_accuracy: 0.1843 - val_loss: 2.6594\n",
            "Epoch 14/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.5833 - loss: 1.3135 - val_accuracy: 0.4316 - val_loss: 1.6377\n",
            "Epoch 15/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 93ms/step - accuracy: 0.5914 - loss: 1.2724 - val_accuracy: 0.5806 - val_loss: 1.3026\n",
            "Epoch 16/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.6227 - loss: 1.2078 - val_accuracy: 0.4228 - val_loss: 1.5893\n",
            "Epoch 17/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 93ms/step - accuracy: 0.5967 - loss: 1.2450 - val_accuracy: 0.5000 - val_loss: 1.4734\n",
            "Epoch 18/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 94ms/step - accuracy: 0.6240 - loss: 1.1734 - val_accuracy: 0.4397 - val_loss: 1.5962\n",
            "Epoch 19/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 94ms/step - accuracy: 0.6265 - loss: 1.1685 - val_accuracy: 0.5962 - val_loss: 1.2545\n",
            "Epoch 20/20\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.6464 - loss: 1.1491 - val_accuracy: 0.4621 - val_loss: 1.5553\n",
            "Restoring model weights from the end of the best epoch: 19.\n"
          ]
        }
      ],
      "source": [
        "# Modelo 1 - QuickDraw-10\n",
        "# Detalles:\n",
        "# Activacion: sigmoid\n",
        "# Perdida: CrossEntropy\n",
        "# Capas: 3\n",
        "# Epocas: 100\n",
        "# Batch size: 100\n",
        "\n",
        "acc_total_1, acc_clase_1, cm_1 = experiment(\n",
        "        train_images_10,\n",
        "        train_labels_10,\n",
        "        val_image_10,\n",
        "        val_labels_10,\n",
        "        test_images_10,\n",
        "        test_labels_10,\n",
        "        layers_size=[512,256],\n",
        "        n_classes=10,\n",
        "        activation='sigmoid',\n",
        "        loss_fn='categorical_crossentropy',\n",
        "        class_names=clases,\n",
        "        epochs=20,\n",
        "        batch_size=32,\n",
        "        n_experiments=5\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cwUV5IR5EpvA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'bandage': 0.425,\n",
              "  'blackberry': 0.21311475409836064,\n",
              "  'castle': 0.8625954198473282,\n",
              "  'flashlight': 0.8275862068965517,\n",
              "  'lion': 0.01904761904761905,\n",
              "  'remote-control': 0.6407766990291263,\n",
              "  'sink': 0.2672413793103448,\n",
              "  'spreadsheet': 0.8016528925619835,\n",
              "  'teapot': 0.7076923076923077,\n",
              "  'trombone': 0.3627450980392157},\n",
              " {'bandage': 0.48333333333333334,\n",
              "  'blackberry': 0.38524590163934425,\n",
              "  'castle': 0.7938931297709924,\n",
              "  'flashlight': 0.853448275862069,\n",
              "  'lion': 0.5238095238095238,\n",
              "  'remote-control': 0.5631067961165048,\n",
              "  'sink': 0.6896551724137931,\n",
              "  'spreadsheet': 0.3305785123966942,\n",
              "  'teapot': 0.8307692307692308,\n",
              "  'trombone': 0.3235294117647059},\n",
              " {'bandage': 0.24166666666666667,\n",
              "  'blackberry': 0.03278688524590164,\n",
              "  'castle': 0.648854961832061,\n",
              "  'flashlight': 0.7586206896551724,\n",
              "  'lion': 0.8952380952380953,\n",
              "  'remote-control': 0.7475728155339806,\n",
              "  'sink': 0.23275862068965517,\n",
              "  'spreadsheet': 0.0,\n",
              "  'teapot': 0.6,\n",
              "  'trombone': 0.4215686274509804},\n",
              " {'bandage': 0.5083333333333333,\n",
              "  'blackberry': 0.319672131147541,\n",
              "  'castle': 0.5572519083969466,\n",
              "  'flashlight': 0.9482758620689655,\n",
              "  'lion': 0.19047619047619047,\n",
              "  'remote-control': 0.7378640776699029,\n",
              "  'sink': 0.4827586206896552,\n",
              "  'spreadsheet': 0.371900826446281,\n",
              "  'teapot': 0.7307692307692307,\n",
              "  'trombone': 0.7352941176470589},\n",
              " {'bandage': 0.5333333333333333,\n",
              "  'blackberry': 0.5,\n",
              "  'castle': 0.6183206106870229,\n",
              "  'flashlight': 0.8448275862068966,\n",
              "  'lion': 0.5047619047619047,\n",
              "  'remote-control': 0.5631067961165048,\n",
              "  'sink': 0.8189655172413793,\n",
              "  'spreadsheet': 0.47107438016528924,\n",
              "  'teapot': 0.8307692307692308,\n",
              "  'trombone': 0.5588235294117647}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc_clase_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.5240137221269296,\n",
              " 0.5849056603773585,\n",
              " 0.4502572898799314,\n",
              " 0.5574614065180102,\n",
              " 0.62778730703259]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc_total_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[ 51,   1,  23,  30,   1,   6,   0,   6,   0,   2],\n",
              "        [  3,  26,  30,  44,   1,   1,   0,  10,   2,   5],\n",
              "        [  0,   0, 113,   1,   0,   3,   1,   8,   0,   5],\n",
              "        [  1,   0,   9,  96,   0,   0,   0,   9,   1,   0],\n",
              "        [  1,   0,   3,   8,   2,   0,   0,  73,   9,   9],\n",
              "        [  0,   0,  28,   1,   1,  66,   1,   4,   1,   1],\n",
              "        [  0,   3,  60,   4,   0,  12,  31,   5,   0,   1],\n",
              "        [  0,   0,   6,   7,   0,   4,   1,  97,   2,   4],\n",
              "        [  2,   2,   4,   8,   1,   4,   0,  17,  92,   0],\n",
              "        [  0,   0,  16,  13,   2,   3,   0,  30,   1,  37]]),\n",
              " array([[ 58,   2,  20,  16,   2,   3,   7,   1,  11,   0],\n",
              "        [  4,  47,  21,  30,   3,   1,   8,   0,   8,   0],\n",
              "        [  0,   0, 104,   3,   2,   2,  14,   0,   2,   4],\n",
              "        [  1,   0,   9,  99,   4,   0,   0,   0,   3,   0],\n",
              "        [  1,   0,   5,  10,  55,   0,   1,   0,  27,   6],\n",
              "        [  0,   1,  15,   0,   3,  58,  21,   0,   5,   0],\n",
              "        [  0,   2,  24,   0,   2,   6,  80,   1,   0,   1],\n",
              "        [  0,   0,   3,  19,  41,   3,   8,  40,   5,   2],\n",
              "        [  2,   2,   2,   7,   5,   2,   2,   0, 108,   0],\n",
              "        [  0,   0,  17,  14,  18,   3,   8,   5,   4,  33]]),\n",
              " array([[29,  1, 11, 32, 33,  8,  0,  0,  2,  4],\n",
              "        [ 1,  4, 10, 69, 26,  2,  0,  0,  3,  7],\n",
              "        [ 0,  0, 85,  6, 16, 15,  1,  0,  0,  8],\n",
              "        [ 1,  0,  5, 88, 20,  0,  0,  0,  2,  0],\n",
              "        [ 0,  0,  0,  2, 94,  1,  0,  0,  3,  5],\n",
              "        [ 0,  0,  8,  1, 10, 77,  1,  0,  1,  5],\n",
              "        [ 0,  3, 42,  7,  4, 19, 27,  0,  0, 14],\n",
              "        [ 0,  0,  2,  6, 99,  5,  1,  0,  1,  7],\n",
              "        [ 1,  0,  2,  4, 39,  5,  0,  0, 78,  1],\n",
              "        [ 0,  0,  5,  8, 41,  3,  0,  0,  2, 43]]),\n",
              " array([[ 61,   2,   2,  38,   0,   5,   1,   0,   1,  10],\n",
              "        [  4,  39,   2,  58,   1,   2,   0,   0,   2,  14],\n",
              "        [  4,   2,  73,  16,   0,  12,   1,   0,   1,  22],\n",
              "        [  1,   0,   2, 110,   0,   0,   0,   0,   0,   3],\n",
              "        [  1,   0,   0,  16,  20,   0,   0,   2,  14,  52],\n",
              "        [  0,   1,   3,   5,   2,  76,   8,   0,   0,   8],\n",
              "        [  1,   7,  14,   8,   0,  17,  56,   0,   0,  13],\n",
              "        [  0,   2,   2,  29,   6,   4,   1,  45,   2,  30],\n",
              "        [  4,   2,   0,  16,   1,   8,   1,   0,  95,   3],\n",
              "        [  0,   0,   2,  19,   0,   3,   1,   0,   2,  75]]),\n",
              " array([[ 64,   2,   6,  18,   2,   3,  12,   0,   9,   4],\n",
              "        [  2,  61,  10,  16,   5,   2,  19,   0,   6,   1],\n",
              "        [  2,   0,  81,   0,   3,   6,  28,   0,   3,   8],\n",
              "        [  1,   2,   5,  98,   4,   0,   3,   0,   3,   0],\n",
              "        [  1,   0,   0,   8,  53,   0,   0,   1,  24,  18],\n",
              "        [  0,   1,   7,   0,   3,  58,  29,   0,   5,   0],\n",
              "        [  0,   2,   8,   0,   2,   7,  95,   1,   0,   1],\n",
              "        [  0,   0,   1,  12,  27,   3,   9,  57,   3,   9],\n",
              "        [  2,   2,   1,   5,   6,   3,   2,   0, 108,   1],\n",
              "        [  0,   0,   8,   9,   6,   3,  12,   4,   3,  57]])]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cm_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "collapsed": true,
        "id": "kX7q-_lZDDCO",
        "outputId": "6244d292-402c-491a-a610-5e1551f38bc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entrenamiento número 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_5', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 193ms/step - accuracy: 0.0912 - loss: 1.0349 - val_accuracy: 0.1037 - val_loss: 1.0106\n",
            "Epoch 2/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 182ms/step - accuracy: 0.0950 - loss: 1.0093 - val_accuracy: 0.0711 - val_loss: 1.0070\n",
            "Epoch 3/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 178ms/step - accuracy: 0.0956 - loss: 1.0066 - val_accuracy: 0.1199 - val_loss: 1.0053\n",
            "Epoch 4/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 189ms/step - accuracy: 0.1127 - loss: 1.0046 - val_accuracy: 0.1023 - val_loss: 1.0029\n",
            "Epoch 5/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 180ms/step - accuracy: 0.1172 - loss: 1.0019 - val_accuracy: 0.1301 - val_loss: 1.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 178ms/step - accuracy: 0.1350 - loss: 1.0009 - val_accuracy: 0.1612 - val_loss: 1.0011\n",
            "Epoch 7/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 187ms/step - accuracy: 0.1490 - loss: 1.0009 - val_accuracy: 0.1592 - val_loss: 1.0009\n",
            "Epoch 8/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step - accuracy: 0.1571 - loss: 1.0008 - val_accuracy: 0.1755 - val_loss: 1.0007\n",
            "Epoch 9/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - accuracy: 0.1660 - loss: 1.0007 - val_accuracy: 0.1443 - val_loss: 1.0012\n",
            "Epoch 10/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - accuracy: 0.1774 - loss: 1.0008 - val_accuracy: 0.1870 - val_loss: 1.0011\n",
            "Epoch 11/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 174ms/step - accuracy: 0.1831 - loss: 1.0007 - val_accuracy: 0.1877 - val_loss: 1.0007\n",
            "Epoch 12/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step - accuracy: 0.1929 - loss: 1.0007 - val_accuracy: 0.2229 - val_loss: 1.0006\n",
            "Epoch 13/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 176ms/step - accuracy: 0.2106 - loss: 1.0006 - val_accuracy: 0.1985 - val_loss: 1.0008\n",
            "Epoch 14/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - accuracy: 0.2221 - loss: 1.0006 - val_accuracy: 0.2127 - val_loss: 1.0009\n",
            "Epoch 15/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.2269 - loss: 1.0006 - val_accuracy: 0.1985 - val_loss: 1.0008\n",
            "Epoch 16/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - accuracy: 0.2241 - loss: 1.0006 - val_accuracy: 0.2331 - val_loss: 1.0006\n",
            "Epoch 17/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 160ms/step - accuracy: 0.2393 - loss: 1.0005 - val_accuracy: 0.2297 - val_loss: 1.0006\n",
            "Epoch 17: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "\n",
            "Entrenamiento número 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_6', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 174ms/step - accuracy: 0.0891 - loss: 1.0768 - val_accuracy: 0.0779 - val_loss: 1.0382\n",
            "Epoch 2/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.0976 - loss: 1.0351 - val_accuracy: 0.0827 - val_loss: 1.0289\n",
            "Epoch 3/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - accuracy: 0.0933 - loss: 1.0272 - val_accuracy: 0.0854 - val_loss: 1.0237\n",
            "Epoch 4/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 160ms/step - accuracy: 0.1000 - loss: 1.0220 - val_accuracy: 0.0718 - val_loss: 1.0163\n",
            "Epoch 5/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - accuracy: 0.1224 - loss: 1.0147 - val_accuracy: 0.1037 - val_loss: 1.0122\n",
            "Epoch 6/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - accuracy: 0.1299 - loss: 1.0108 - val_accuracy: 0.1125 - val_loss: 1.0080\n",
            "Epoch 7/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - accuracy: 0.1348 - loss: 1.0068 - val_accuracy: 0.1436 - val_loss: 1.0026\n",
            "Epoch 8/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - accuracy: 0.1419 - loss: 1.0017 - val_accuracy: 0.1389 - val_loss: 1.0006\n",
            "Epoch 9/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - accuracy: 0.1363 - loss: 1.0007 - val_accuracy: 0.1240 - val_loss: 1.0007\n",
            "Epoch 10/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 160ms/step - accuracy: 0.1509 - loss: 1.0007 - val_accuracy: 0.1551 - val_loss: 1.0007\n",
            "Epoch 11/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.1567 - loss: 1.0007 - val_accuracy: 0.1362 - val_loss: 1.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - accuracy: 0.1737 - loss: 1.0006 - val_accuracy: 0.1423 - val_loss: 1.0008\n",
            "Epoch 13/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - accuracy: 0.1881 - loss: 1.0006 - val_accuracy: 0.1890 - val_loss: 1.0006\n",
            "Epoch 14/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 160ms/step - accuracy: 0.1847 - loss: 1.0006 - val_accuracy: 0.1660 - val_loss: 1.0005\n",
            "Epoch 15/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - accuracy: 0.2097 - loss: 1.0005 - val_accuracy: 0.1755 - val_loss: 1.0006\n",
            "Epoch 16/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 159ms/step - accuracy: 0.2126 - loss: 1.0005 - val_accuracy: 0.2446 - val_loss: 1.0006\n",
            "Epoch 17/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - accuracy: 0.2213 - loss: 1.0005 - val_accuracy: 0.2080 - val_loss: 1.0008\n",
            "Epoch 18/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - accuracy: 0.2361 - loss: 1.0005 - val_accuracy: 0.2554 - val_loss: 1.0006\n",
            "Epoch 19/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 160ms/step - accuracy: 0.2280 - loss: 1.0005 - val_accuracy: 0.2019 - val_loss: 1.0007\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n",
            "\n",
            "Entrenamiento número 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_7', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 170ms/step - accuracy: 0.1044 - loss: 1.0610 - val_accuracy: 0.1003 - val_loss: 1.0082\n",
            "Epoch 2/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - accuracy: 0.1383 - loss: 1.0044 - val_accuracy: 0.1382 - val_loss: 1.0012\n",
            "Epoch 3/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - accuracy: 0.1478 - loss: 1.0009 - val_accuracy: 0.1111 - val_loss: 1.0011\n",
            "Epoch 4/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.1439 - loss: 1.0009 - val_accuracy: 0.1301 - val_loss: 1.0009\n",
            "Epoch 5/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - accuracy: 0.1634 - loss: 1.0008 - val_accuracy: 0.1402 - val_loss: 1.0011\n",
            "Epoch 6/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - accuracy: 0.1775 - loss: 1.0008 - val_accuracy: 0.1606 - val_loss: 1.0008\n",
            "Epoch 7/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.1792 - loss: 1.0007 - val_accuracy: 0.1667 - val_loss: 1.0009\n",
            "Epoch 8/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - accuracy: 0.2133 - loss: 1.0007 - val_accuracy: 0.1924 - val_loss: 1.0007\n",
            "Epoch 9/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - accuracy: 0.1969 - loss: 1.0007 - val_accuracy: 0.2080 - val_loss: 1.0008\n",
            "Epoch 10/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 159ms/step - accuracy: 0.2060 - loss: 1.0007 - val_accuracy: 0.2093 - val_loss: 1.0006\n",
            "Epoch 11/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.2176 - loss: 1.0006 - val_accuracy: 0.2168 - val_loss: 1.0008\n",
            "Epoch 12/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.2302 - loss: 1.0006 - val_accuracy: 0.1978 - val_loss: 1.0008\n",
            "Epoch 13/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - accuracy: 0.2346 - loss: 1.0006 - val_accuracy: 0.2087 - val_loss: 1.0007\n",
            "Epoch 14/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - accuracy: 0.2321 - loss: 1.0006 - val_accuracy: 0.1883 - val_loss: 1.0007\n",
            "Epoch 15/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - accuracy: 0.2402 - loss: 1.0005 - val_accuracy: 0.2270 - val_loss: 1.0007\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\n",
            "Entrenamiento número 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_8', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.1050 - loss: 1.0540 - val_accuracy: 0.1186 - val_loss: 1.0181\n",
            "Epoch 2/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - accuracy: 0.1188 - loss: 1.0152 - val_accuracy: 0.1172 - val_loss: 1.0074\n",
            "Epoch 3/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - accuracy: 0.1211 - loss: 1.0055 - val_accuracy: 0.0962 - val_loss: 1.0037\n",
            "Epoch 4/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - accuracy: 0.1332 - loss: 1.0029 - val_accuracy: 0.0752 - val_loss: 1.0014\n",
            "Epoch 5/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - accuracy: 0.1212 - loss: 1.0010 - val_accuracy: 0.1369 - val_loss: 1.0008\n",
            "Epoch 6/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - accuracy: 0.1379 - loss: 1.0009 - val_accuracy: 0.1633 - val_loss: 1.0008\n",
            "Epoch 7/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - accuracy: 0.1439 - loss: 1.0008 - val_accuracy: 0.1328 - val_loss: 1.0009\n",
            "Epoch 8/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 176ms/step - accuracy: 0.1484 - loss: 1.0008 - val_accuracy: 0.1348 - val_loss: 1.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 182ms/step - accuracy: 0.1509 - loss: 1.0008 - val_accuracy: 0.1904 - val_loss: 1.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 185ms/step - accuracy: 0.1785 - loss: 1.0008 - val_accuracy: 0.1633 - val_loss: 1.0008\n",
            "Epoch 11/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 183ms/step - accuracy: 0.1792 - loss: 1.0007 - val_accuracy: 0.1782 - val_loss: 1.0008\n",
            "Epoch 12/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 173ms/step - accuracy: 0.1825 - loss: 1.0007 - val_accuracy: 0.1423 - val_loss: 1.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - accuracy: 0.1839 - loss: 1.0007 - val_accuracy: 0.1802 - val_loss: 1.0008\n",
            "Epoch 14/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - accuracy: 0.1980 - loss: 1.0006 - val_accuracy: 0.2317 - val_loss: 1.0006\n",
            "Epoch 15/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - accuracy: 0.2144 - loss: 1.0006 - val_accuracy: 0.1748 - val_loss: 1.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - accuracy: 0.2150 - loss: 1.0007 - val_accuracy: 0.2093 - val_loss: 1.0006\n",
            "Epoch 17/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.2358 - loss: 1.0005 - val_accuracy: 0.2622 - val_loss: 1.0006\n",
            "Epoch 18/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - accuracy: 0.2442 - loss: 1.0005 - val_accuracy: 0.2358 - val_loss: 1.0005\n",
            "Epoch 19/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - accuracy: 0.2593 - loss: 1.0005 - val_accuracy: 0.2351 - val_loss: 1.0008\n",
            "Epoch 20/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - accuracy: 0.2691 - loss: 1.0005 - val_accuracy: 0.2412 - val_loss: 1.0005\n",
            "Epoch 21/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - accuracy: 0.2604 - loss: 1.0005 - val_accuracy: 0.2520 - val_loss: 1.0007\n",
            "Epoch 22/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.2598 - loss: 1.0005 - val_accuracy: 0.2839 - val_loss: 1.0005\n",
            "Epoch 23/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - accuracy: 0.2649 - loss: 1.0005 - val_accuracy: 0.2859 - val_loss: 1.0004\n",
            "Epoch 24/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - accuracy: 0.2998 - loss: 1.0004 - val_accuracy: 0.2263 - val_loss: 1.0006\n",
            "Epoch 25/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - accuracy: 0.2928 - loss: 1.0004 - val_accuracy: 0.2317 - val_loss: 1.0006\n",
            "Epoch 26/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - accuracy: 0.3019 - loss: 1.0004 - val_accuracy: 0.2893 - val_loss: 1.0005\n",
            "Epoch 27/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 173ms/step - accuracy: 0.3099 - loss: 1.0004 - val_accuracy: 0.3022 - val_loss: 1.0004\n",
            "Epoch 28/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - accuracy: 0.3037 - loss: 1.0004 - val_accuracy: 0.2656 - val_loss: 1.0005\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 23.\n",
            "\n",
            "Entrenamiento número 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_9', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 168ms/step - accuracy: 0.0903 - loss: 1.0429 - val_accuracy: 0.1023 - val_loss: 1.0084\n",
            "Epoch 2/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.0824 - loss: 1.0064 - val_accuracy: 0.1037 - val_loss: 1.0012\n",
            "Epoch 3/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - accuracy: 0.0987 - loss: 1.0011 - val_accuracy: 0.1030 - val_loss: 1.0011\n",
            "Epoch 4/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - accuracy: 0.1089 - loss: 1.0010 - val_accuracy: 0.1003 - val_loss: 1.0009\n",
            "Epoch 5/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.1212 - loss: 1.0009 - val_accuracy: 0.1253 - val_loss: 1.0011\n",
            "Epoch 6/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - accuracy: 0.1300 - loss: 1.0009 - val_accuracy: 0.1050 - val_loss: 1.0012\n",
            "Epoch 7/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - accuracy: 0.1383 - loss: 1.0009 - val_accuracy: 0.1585 - val_loss: 1.0008\n",
            "Epoch 8/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - accuracy: 0.1502 - loss: 1.0008 - val_accuracy: 0.1423 - val_loss: 1.0008\n",
            "Epoch 9/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - accuracy: 0.1637 - loss: 1.0007 - val_accuracy: 0.1430 - val_loss: 1.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - accuracy: 0.1791 - loss: 1.0008 - val_accuracy: 0.1619 - val_loss: 1.0008\n",
            "Epoch 11/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - accuracy: 0.1847 - loss: 1.0007 - val_accuracy: 0.1809 - val_loss: 1.0008\n",
            "Epoch 12/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - accuracy: 0.1955 - loss: 1.0007 - val_accuracy: 0.1626 - val_loss: 1.0010\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n"
          ]
        }
      ],
      "source": [
        "# Modelo 2 - QuickDraw-10\n",
        "# Detalles:\n",
        "# Activacion: sigmoid\n",
        "# Perdida: CrossEntropy\n",
        "# Capas: 3\n",
        "# Epocas: 20\n",
        "# Batch size: 1000\n",
        "\n",
        "acc_total_2, acc_clase_2, cm_2 = experiment(\n",
        "        train_images_10,\n",
        "        train_labels_10,\n",
        "        val_image_10,\n",
        "        val_labels_10,\n",
        "        test_images_10,\n",
        "        test_labels_10,\n",
        "        layers_size=[512, 256, 128],\n",
        "        n_classes=10,\n",
        "        activation='sigmoid',\n",
        "        loss_fn='categorical_hinge',\n",
        "        class_names=clases,\n",
        "        epochs=50,\n",
        "        batch_size=128,\n",
        "        n_experiments=5\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'bandage': 0.16666666666666666,\n",
              "  'blackberry': 0.00819672131147541,\n",
              "  'castle': 0.030534351145038167,\n",
              "  'flashlight': 0.3103448275862069,\n",
              "  'lion': 0.3142857142857143,\n",
              "  'remote-control': 0.6504854368932039,\n",
              "  'sink': 0.05172413793103448,\n",
              "  'spreadsheet': 0.0743801652892562,\n",
              "  'teapot': 0.5230769230769231,\n",
              "  'trombone': 0.029411764705882353},\n",
              " {'bandage': 0.13333333333333333,\n",
              "  'blackberry': 0.01639344262295082,\n",
              "  'castle': 0.25190839694656486,\n",
              "  'flashlight': 0.13793103448275862,\n",
              "  'lion': 0.009523809523809525,\n",
              "  'remote-control': 0.2912621359223301,\n",
              "  'sink': 0.19827586206896552,\n",
              "  'spreadsheet': 0.19834710743801653,\n",
              "  'teapot': 0.046153846153846156,\n",
              "  'trombone': 0.46078431372549017},\n",
              " {'bandage': 0.1,\n",
              "  'blackberry': 0.00819672131147541,\n",
              "  'castle': 0.015267175572519083,\n",
              "  'flashlight': 0.15517241379310345,\n",
              "  'lion': 0.2761904761904762,\n",
              "  'remote-control': 0.8543689320388349,\n",
              "  'sink': 0.07758620689655173,\n",
              "  'spreadsheet': 0.10743801652892562,\n",
              "  'teapot': 0.38461538461538464,\n",
              "  'trombone': 0.14705882352941177},\n",
              " {'bandage': 0.24166666666666667,\n",
              "  'blackberry': 0.1721311475409836,\n",
              "  'castle': 0.04580152671755725,\n",
              "  'flashlight': 0.3448275862068966,\n",
              "  'lion': 0.17142857142857143,\n",
              "  'remote-control': 0.5825242718446602,\n",
              "  'sink': 0.11206896551724138,\n",
              "  'spreadsheet': 0.5041322314049587,\n",
              "  'teapot': 0.36153846153846153,\n",
              "  'trombone': 0.23529411764705882},\n",
              " {'bandage': 0.05,\n",
              "  'blackberry': 0.319672131147541,\n",
              "  'castle': 0.1984732824427481,\n",
              "  'flashlight': 0.1206896551724138,\n",
              "  'lion': 0.0,\n",
              "  'remote-control': 0.4368932038834951,\n",
              "  'sink': 0.14655172413793102,\n",
              "  'spreadsheet': 0.12396694214876033,\n",
              "  'teapot': 0.2692307692307692,\n",
              "  'trombone': 0.0196078431372549}]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc_clase_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.2118353344768439,\n",
              " 0.16981132075471697,\n",
              " 0.2032590051457976,\n",
              " 0.27358490566037735,\n",
              " 0.17066895368782162]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc_total_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[20,  0,  2, 21, 28, 25,  7,  5, 12,  0],\n",
              "        [12,  1,  4, 25, 30, 17,  5,  5, 22,  1],\n",
              "        [13,  0,  4, 21, 22, 39,  4, 10, 12,  6],\n",
              "        [11,  1,  3, 36, 27, 10,  5,  4, 19,  0],\n",
              "        [17,  0,  4,  5, 33, 25,  7,  6,  8,  0],\n",
              "        [ 4,  0,  1,  4, 13, 67,  1,  1,  9,  3],\n",
              "        [ 3,  0,  2, 16, 26, 47,  6,  6,  4,  6],\n",
              "        [10,  0,  4, 14, 45, 16,  7,  9, 16,  0],\n",
              "        [ 7,  0,  0,  5, 20, 23,  4,  2, 68,  1],\n",
              "        [ 9,  0,  1, 16, 37, 18,  5,  9,  4,  3]]),\n",
              " array([[16,  1, 25,  2,  4,  4,  8, 14,  2, 44],\n",
              "        [15,  2, 39,  4,  1,  1,  7, 12,  4, 37],\n",
              "        [ 3,  0, 33,  3,  1, 12, 21, 22,  4, 32],\n",
              "        [13,  2, 36, 16,  3,  4,  4, 10,  1, 27],\n",
              "        [32,  6, 12,  3,  1,  5,  0,  9,  1, 36],\n",
              "        [ 3,  1,  3,  0,  0, 30, 21,  9,  0, 36],\n",
              "        [ 2,  0, 20,  4,  0,  7, 23, 15,  2, 43],\n",
              "        [18,  0,  6,  4,  1,  2,  7, 24,  1, 58],\n",
              "        [21,  3, 18,  9, 10, 13,  4, 10,  6, 36],\n",
              "        [11,  2, 20,  3,  0,  3,  3, 10,  3, 47]]),\n",
              " array([[12,  0,  0, 14, 15, 34, 18,  6,  9, 12],\n",
              "        [ 6,  1,  0, 12, 31, 10, 16,  9, 14, 23],\n",
              "        [ 4,  1,  2,  5, 26, 54, 12,  8, 10,  9],\n",
              "        [11,  1,  0, 18, 24,  3, 12,  4, 15, 28],\n",
              "        [ 6,  0,  0,  6, 29,  8, 30,  3, 10, 13],\n",
              "        [ 1,  0,  0,  0,  5, 88,  1,  0,  6,  2],\n",
              "        [ 3,  1,  2,  4,  7, 72,  9, 12,  0,  6],\n",
              "        [ 6,  0,  0,  9, 30, 15, 17, 13, 14, 17],\n",
              "        [ 5,  1,  0,  9, 36, 16,  7,  1, 50,  5],\n",
              "        [ 2,  0,  1,  4, 27, 19, 20,  7,  7, 15]]),\n",
              " array([[29,  6,  1,  7, 11, 31,  7, 15,  2, 11],\n",
              "        [19, 21,  0, 23,  8,  7,  7, 16,  6, 15],\n",
              "        [22,  9,  6,  7, 14, 34, 13, 10,  3, 13],\n",
              "        [ 5,  6,  0, 40, 16,  9,  2, 20,  0, 18],\n",
              "        [ 3,  1,  0,  6, 18, 24,  3, 35,  2, 13],\n",
              "        [11,  5,  3,  3,  6, 60, 11,  1,  0,  3],\n",
              "        [20, 22,  5,  7,  4, 32, 13,  2,  0, 11],\n",
              "        [ 2,  6,  2, 11, 10, 12,  1, 61,  1, 15],\n",
              "        [ 8,  4,  0, 13,  9, 30,  1,  9, 47,  9],\n",
              "        [ 2,  0,  1,  8, 22, 21,  2, 22,  0, 24]]),\n",
              " array([[ 6, 27, 18, 13,  1, 17, 15, 12, 11,  0],\n",
              "        [ 2, 39, 10, 18,  0,  8, 26, 11,  8,  0],\n",
              "        [ 1, 28, 26, 18,  3, 17, 16, 15,  6,  1],\n",
              "        [ 2, 21, 17, 14,  1, 14, 33,  4, 10,  0],\n",
              "        [ 5, 18, 12, 14,  0, 14, 19,  4, 16,  3],\n",
              "        [ 0, 11, 12, 10,  3, 45,  6, 11,  5,  0],\n",
              "        [ 1, 23, 11, 15,  1, 20, 17, 21,  6,  1],\n",
              "        [ 4, 22, 16, 13,  0,  9, 27, 15, 14,  1],\n",
              "        [ 8, 23,  9,  8,  1, 14, 28,  4, 35,  0],\n",
              "        [ 0, 12, 16,  9,  1, 16, 28, 14,  4,  2]])]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cm_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tRMvGYDiEGz2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entrenamiento número 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_10', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.0939 - loss: 1.1701 - val_accuracy: 0.1043 - val_loss: 1.0456\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 329ms/step - accuracy: 0.1070 - loss: 1.0445 - val_accuracy: 0.1030 - val_loss: 1.0389\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 335ms/step - accuracy: 0.0974 - loss: 1.0373 - val_accuracy: 0.0996 - val_loss: 1.0272\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 324ms/step - accuracy: 0.1010 - loss: 1.0266 - val_accuracy: 0.1077 - val_loss: 1.0235\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 315ms/step - accuracy: 0.1087 - loss: 1.0229 - val_accuracy: 0.1247 - val_loss: 1.0210\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 310ms/step - accuracy: 0.1188 - loss: 1.0202 - val_accuracy: 0.1043 - val_loss: 1.0182\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 312ms/step - accuracy: 0.1314 - loss: 1.0141 - val_accuracy: 0.1023 - val_loss: 1.0138\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 310ms/step - accuracy: 0.1258 - loss: 1.0126 - val_accuracy: 0.1430 - val_loss: 1.0091\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 313ms/step - accuracy: 0.1235 - loss: 1.0110 - val_accuracy: 0.1274 - val_loss: 1.0091\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 325ms/step - accuracy: 0.1482 - loss: 1.0085 - val_accuracy: 0.1057 - val_loss: 1.0082\n",
            "Epoch 11/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 318ms/step - accuracy: 0.1294 - loss: 1.0071 - val_accuracy: 0.1389 - val_loss: 1.0043\n",
            "Epoch 12/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 305ms/step - accuracy: 0.1334 - loss: 1.0063 - val_accuracy: 0.1660 - val_loss: 1.0068\n",
            "Epoch 13/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 307ms/step - accuracy: 0.1504 - loss: 1.0058 - val_accuracy: 0.0949 - val_loss: 1.0082\n",
            "Epoch 14/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 309ms/step - accuracy: 0.1169 - loss: 1.0067 - val_accuracy: 0.1606 - val_loss: 1.0051\n",
            "Epoch 15/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 310ms/step - accuracy: 0.1417 - loss: 1.0060 - val_accuracy: 0.1152 - val_loss: 1.0087\n",
            "Epoch 16/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 325ms/step - accuracy: 0.1552 - loss: 1.0065 - val_accuracy: 0.1402 - val_loss: 1.0053\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\n",
            "Entrenamiento número 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_11', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 415ms/step - accuracy: 0.1028 - loss: 1.1509 - val_accuracy: 0.0989 - val_loss: 1.0618\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 324ms/step - accuracy: 0.1060 - loss: 1.0530 - val_accuracy: 0.1301 - val_loss: 1.0316\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 319ms/step - accuracy: 0.1076 - loss: 1.0333 - val_accuracy: 0.1362 - val_loss: 1.0231\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 318ms/step - accuracy: 0.1206 - loss: 1.0233 - val_accuracy: 0.1247 - val_loss: 1.0186\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 331ms/step - accuracy: 0.1174 - loss: 1.0196 - val_accuracy: 0.1179 - val_loss: 1.0161\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 321ms/step - accuracy: 0.1224 - loss: 1.0172 - val_accuracy: 0.1009 - val_loss: 1.0206\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 314ms/step - accuracy: 0.1026 - loss: 1.0191 - val_accuracy: 0.1633 - val_loss: 1.0165\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 310ms/step - accuracy: 0.1501 - loss: 1.0167 - val_accuracy: 0.1389 - val_loss: 1.0180\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 310ms/step - accuracy: 0.1218 - loss: 1.0177 - val_accuracy: 0.1355 - val_loss: 1.0195\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 308ms/step - accuracy: 0.1276 - loss: 1.0177 - val_accuracy: 0.1030 - val_loss: 1.0170\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\n",
            "Entrenamiento número 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_12', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.0949 - loss: 1.1068 - val_accuracy: 0.0989 - val_loss: 1.0391\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 321ms/step - accuracy: 0.1122 - loss: 1.0314 - val_accuracy: 0.1023 - val_loss: 1.0285\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 324ms/step - accuracy: 0.1062 - loss: 1.0283 - val_accuracy: 0.1104 - val_loss: 1.0261\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 306ms/step - accuracy: 0.1225 - loss: 1.0256 - val_accuracy: 0.1057 - val_loss: 1.0265\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 318ms/step - accuracy: 0.1175 - loss: 1.0231 - val_accuracy: 0.1152 - val_loss: 1.0201\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 309ms/step - accuracy: 0.1241 - loss: 1.0186 - val_accuracy: 0.1274 - val_loss: 1.0166\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 324ms/step - accuracy: 0.1243 - loss: 1.0176 - val_accuracy: 0.1524 - val_loss: 1.0134\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 323ms/step - accuracy: 0.1379 - loss: 1.0150 - val_accuracy: 0.1477 - val_loss: 1.0164\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 310ms/step - accuracy: 0.1589 - loss: 1.0150 - val_accuracy: 0.1050 - val_loss: 1.0175\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 314ms/step - accuracy: 0.1207 - loss: 1.0161 - val_accuracy: 0.1565 - val_loss: 1.0171\n",
            "Epoch 11/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 308ms/step - accuracy: 0.1449 - loss: 1.0168 - val_accuracy: 0.1457 - val_loss: 1.0164\n",
            "Epoch 12/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 313ms/step - accuracy: 0.1478 - loss: 1.0165 - val_accuracy: 0.1355 - val_loss: 1.0162\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\n",
            "Entrenamiento número 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_13', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.1003 - loss: 1.1394 - val_accuracy: 0.1023 - val_loss: 1.0620\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 329ms/step - accuracy: 0.1136 - loss: 1.0534 - val_accuracy: 0.1159 - val_loss: 1.0350\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 316ms/step - accuracy: 0.1082 - loss: 1.0361 - val_accuracy: 0.1118 - val_loss: 1.0310\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 319ms/step - accuracy: 0.1092 - loss: 1.0284 - val_accuracy: 0.1145 - val_loss: 1.0177\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 334ms/step - accuracy: 0.1135 - loss: 1.0184 - val_accuracy: 0.1565 - val_loss: 1.0155\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 318ms/step - accuracy: 0.1326 - loss: 1.0177 - val_accuracy: 0.1152 - val_loss: 1.0163\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 313ms/step - accuracy: 0.1187 - loss: 1.0181 - val_accuracy: 0.1226 - val_loss: 1.0194\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 315ms/step - accuracy: 0.1275 - loss: 1.0183 - val_accuracy: 0.1016 - val_loss: 1.0175\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 315ms/step - accuracy: 0.1174 - loss: 1.0175 - val_accuracy: 0.1551 - val_loss: 1.0165\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 313ms/step - accuracy: 0.1322 - loss: 1.0181 - val_accuracy: 0.1518 - val_loss: 1.0164\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\n",
            "Entrenamiento número 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_14', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 345ms/step - accuracy: 0.0990 - loss: 1.2119 - val_accuracy: 0.1104 - val_loss: 1.0769\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 320ms/step - accuracy: 0.1097 - loss: 1.0562 - val_accuracy: 0.1416 - val_loss: 1.0354\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 314ms/step - accuracy: 0.1067 - loss: 1.0360 - val_accuracy: 0.1003 - val_loss: 1.0360\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 318ms/step - accuracy: 0.1120 - loss: 1.0331 - val_accuracy: 0.1192 - val_loss: 1.0304\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 318ms/step - accuracy: 0.1070 - loss: 1.0315 - val_accuracy: 0.1050 - val_loss: 1.0293\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 310ms/step - accuracy: 0.1135 - loss: 1.0305 - val_accuracy: 0.1131 - val_loss: 1.0335\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 334ms/step - accuracy: 0.1079 - loss: 1.0302 - val_accuracy: 0.1165 - val_loss: 1.0278\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 319ms/step - accuracy: 0.1108 - loss: 1.0292 - val_accuracy: 0.1009 - val_loss: 1.0265\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 322ms/step - accuracy: 0.1156 - loss: 1.0275 - val_accuracy: 0.1131 - val_loss: 1.0269\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 321ms/step - accuracy: 0.1202 - loss: 1.0265 - val_accuracy: 0.1504 - val_loss: 1.0243\n",
            "Epoch 11/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 323ms/step - accuracy: 0.1489 - loss: 1.0221 - val_accuracy: 0.1084 - val_loss: 1.0233\n",
            "Epoch 12/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 315ms/step - accuracy: 0.1399 - loss: 1.0198 - val_accuracy: 0.1999 - val_loss: 1.0142\n",
            "Epoch 13/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 346ms/step - accuracy: 0.1781 - loss: 1.0140 - val_accuracy: 0.1463 - val_loss: 1.0150\n",
            "Epoch 14/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 333ms/step - accuracy: 0.1675 - loss: 1.0152 - val_accuracy: 0.1741 - val_loss: 1.0146\n",
            "Epoch 15/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 330ms/step - accuracy: 0.1548 - loss: 1.0159 - val_accuracy: 0.1226 - val_loss: 1.0136\n",
            "Epoch 16/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 329ms/step - accuracy: 0.1521 - loss: 1.0154 - val_accuracy: 0.1944 - val_loss: 1.0137\n",
            "Epoch 17/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 317ms/step - accuracy: 0.1797 - loss: 1.0151 - val_accuracy: 0.1958 - val_loss: 1.0150\n",
            "Epoch 18/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 315ms/step - accuracy: 0.1775 - loss: 1.0149 - val_accuracy: 0.1463 - val_loss: 1.0138\n",
            "Epoch 19/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 329ms/step - accuracy: 0.1632 - loss: 1.0154 - val_accuracy: 0.1897 - val_loss: 1.0137\n",
            "Epoch 20/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 324ms/step - accuracy: 0.1726 - loss: 1.0152 - val_accuracy: 0.1972 - val_loss: 1.0142\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 15.\n"
          ]
        }
      ],
      "source": [
        "# Modelo 3 - QuickDraw-10\n",
        "# Detalles:\n",
        "# Activacion: tanh\n",
        "# Perdida: Categorical Hinge\n",
        "# Capas: 4\n",
        "# Epocas: 100\n",
        "# Batch size: 512\n",
        "\n",
        "acc_total_3, acc_clase_3, cm_3 = experiment(\n",
        "        train_images_10,\n",
        "        train_labels_10,\n",
        "        val_image_10,\n",
        "        val_labels_10,\n",
        "        test_images_10,\n",
        "        test_labels_10,\n",
        "        layers_size=[512, 256, 128, 64],\n",
        "        n_classes=10,\n",
        "        activation='tanh',\n",
        "        loss_fn='categorical_hinge',\n",
        "        class_names=clases,\n",
        "        epochs=100,\n",
        "        batch_size=512,\n",
        "        n_experiments=5\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'bandage': 0.016666666666666666,\n",
              "  'blackberry': 0.0,\n",
              "  'castle': 0.0,\n",
              "  'flashlight': 0.0,\n",
              "  'lion': 0.9904761904761905,\n",
              "  'remote-control': 0.3592233009708738,\n",
              "  'sink': 0.0,\n",
              "  'spreadsheet': 0.0,\n",
              "  'teapot': 0.023076923076923078,\n",
              "  'trombone': 0.0},\n",
              " {'bandage': 0.0,\n",
              "  'blackberry': 0.0,\n",
              "  'castle': 0.4351145038167939,\n",
              "  'flashlight': 0.0,\n",
              "  'lion': 0.01904761904761905,\n",
              "  'remote-control': 0.7475728155339806,\n",
              "  'sink': 0.0,\n",
              "  'spreadsheet': 0.0,\n",
              "  'teapot': 0.0,\n",
              "  'trombone': 0.0},\n",
              " {'bandage': 0.0,\n",
              "  'blackberry': 0.00819672131147541,\n",
              "  'castle': 0.0,\n",
              "  'flashlight': 0.3275862068965517,\n",
              "  'lion': 0.009523809523809525,\n",
              "  'remote-control': 0.8640776699029126,\n",
              "  'sink': 0.0,\n",
              "  'spreadsheet': 0.04132231404958678,\n",
              "  'teapot': 0.23076923076923078,\n",
              "  'trombone': 0.21568627450980393},\n",
              " {'bandage': 0.008333333333333333,\n",
              "  'blackberry': 0.0,\n",
              "  'castle': 0.0,\n",
              "  'flashlight': 0.0,\n",
              "  'lion': 0.0,\n",
              "  'remote-control': 0.47572815533980584,\n",
              "  'sink': 0.008620689655172414,\n",
              "  'spreadsheet': 0.0,\n",
              "  'teapot': 0.23846153846153847,\n",
              "  'trombone': 0.9411764705882353},\n",
              " {'bandage': 0.0,\n",
              "  'blackberry': 0.05737704918032787,\n",
              "  'castle': 0.06870229007633588,\n",
              "  'flashlight': 0.0,\n",
              "  'lion': 0.0,\n",
              "  'remote-control': 0.941747572815534,\n",
              "  'sink': 0.13793103448275862,\n",
              "  'spreadsheet': 0.0,\n",
              "  'teapot': 0.046153846153846156,\n",
              "  'trombone': 0.0}]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc_clase_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.12521440823327615,\n",
              " 0.11663807890222985,\n",
              " 0.1595197255574614,\n",
              " 0.15265866209262435,\n",
              " 0.11578044596912522]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc_total_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[  2,   0,   0,   0, 117,   1,   0,   0,   0,   0],\n",
              "        [  1,   0,   0,   0, 121,   0,   0,   0,   0,   0],\n",
              "        [  1,   1,   0,   0, 120,   6,   0,   0,   3,   0],\n",
              "        [  0,   0,   0,   0, 116,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0, 104,   0,   0,   0,   1,   0],\n",
              "        [  1,   0,   2,   1,  60,  37,   0,   0,   2,   0],\n",
              "        [  1,   0,   0,   1,  96,  15,   0,   0,   3,   0],\n",
              "        [  0,   0,   0,   0, 118,   3,   0,   0,   0,   0],\n",
              "        [  1,   0,   0,   0, 126,   0,   0,   0,   3,   0],\n",
              "        [  0,   0,   0,   0, 101,   1,   0,   0,   0,   0]]),\n",
              " array([[ 0,  0, 48,  0,  4, 67,  1,  0,  0,  0],\n",
              "        [ 0,  0, 81,  0,  4, 37,  0,  0,  0,  0],\n",
              "        [ 0,  0, 57,  0,  0, 73,  1,  0,  0,  0],\n",
              "        [ 0,  0, 75,  0,  3, 38,  0,  0,  0,  0],\n",
              "        [ 0,  0, 73,  0,  2, 30,  0,  0,  0,  0],\n",
              "        [ 0,  0, 26,  0,  0, 77,  0,  0,  0,  0],\n",
              "        [ 0,  0, 30,  0,  0, 84,  0,  2,  0,  0],\n",
              "        [ 0,  0, 86,  0,  2, 33,  0,  0,  0,  0],\n",
              "        [ 0,  0, 81,  0,  2, 47,  0,  0,  0,  0],\n",
              "        [ 0,  0, 66,  0,  3, 33,  0,  0,  0,  0]]),\n",
              " array([[ 0,  3,  0, 29,  1, 67,  0,  1, 10,  9],\n",
              "        [ 0,  1,  0, 31,  0, 48,  0,  2, 13, 27],\n",
              "        [ 0,  2,  0, 10,  2, 95,  0,  3, 13,  6],\n",
              "        [ 0,  1,  0, 38,  0, 43,  0,  1, 15, 18],\n",
              "        [ 0,  0,  0, 10,  1, 57,  0,  3,  5, 29],\n",
              "        [ 0,  1,  0,  4,  1, 89,  0,  1,  0,  7],\n",
              "        [ 0,  0,  0, 13,  0, 91,  0,  2,  5,  5],\n",
              "        [ 0,  1,  0, 20,  0, 67,  0,  5,  5, 23],\n",
              "        [ 0,  2,  0, 19,  0, 65,  0,  1, 30, 13],\n",
              "        [ 0,  0,  0,  8,  0, 60,  0,  4,  8, 22]]),\n",
              " array([[  1,   0,   0,   0,   0,  15,   0,   0,  17,  87],\n",
              "        [  0,   0,   0,   0,   0,  13,   0,   0,  13,  96],\n",
              "        [  0,   0,   0,   0,   0,  30,   1,   0,  10,  90],\n",
              "        [  0,   0,   0,   0,   0,   2,   0,   0,   5, 109],\n",
              "        [  0,   0,   0,   0,   0,   2,   0,   0,  10,  93],\n",
              "        [  2,   0,   0,   0,   0,  49,   3,   1,   4,  44],\n",
              "        [  0,   0,   0,   0,   0,  48,   1,   1,   6,  60],\n",
              "        [  0,   0,   0,   0,   0,  11,   1,   0,   3, 106],\n",
              "        [  0,   0,   0,   0,   0,   5,   0,   0,  31,  94],\n",
              "        [  0,   0,   0,   0,   0,   4,   0,   0,   2,  96]]),\n",
              " array([[  0,   5,  11,   0,   0,  81,  23,   0,   0,   0],\n",
              "        [  0,   7,  17,   0,   0,  33,  64,   0,   1,   0],\n",
              "        [  0,   4,   9,   0,   0, 103,  15,   0,   0,   0],\n",
              "        [  0,   5,  31,   0,   0,  24,  56,   0,   0,   0],\n",
              "        [  0,   0,   8,   0,   0,  55,  41,   0,   1,   0],\n",
              "        [  0,   0,   0,   0,   0,  97,   6,   0,   0,   0],\n",
              "        [  0,   4,   6,   0,   0,  90,  16,   0,   0,   0],\n",
              "        [  0,   1,  13,   0,   0,  72,  35,   0,   0,   0],\n",
              "        [  0,   2,   8,   0,   0,  57,  57,   0,   6,   0],\n",
              "        [  0,   1,   6,   0,   0,  69,  26,   0,   0,   0]])]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cm_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFUn89PMI5Kh"
      },
      "source": [
        "Experimentos para QuickDraw-Animals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "nVX-q6E4OYc3"
      },
      "outputs": [],
      "source": [
        "clases = ['sheep', 'bear', 'bee', 'cat', 'camel', 'cow', 'crab', 'crocodile', 'duck', 'elephant', 'dog', 'giraffe']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "0w2q9DXBI9WQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entrenamiento número 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_16', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 98ms/step - accuracy: 0.0963 - loss: 2.5023 - val_accuracy: 0.1161 - val_loss: 2.4685\n",
            "Epoch 2/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 92ms/step - accuracy: 0.1416 - loss: 2.4436 - val_accuracy: 0.0856 - val_loss: 2.4171\n",
            "Epoch 3/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.2122 - loss: 2.3572 - val_accuracy: 0.2922 - val_loss: 2.2833\n",
            "Epoch 4/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.2561 - loss: 2.2615 - val_accuracy: 0.2906 - val_loss: 2.1848\n",
            "Epoch 5/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.3035 - loss: 2.1509 - val_accuracy: 0.3383 - val_loss: 2.0856\n",
            "Epoch 6/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.3427 - loss: 2.0544 - val_accuracy: 0.3444 - val_loss: 2.0594\n",
            "Epoch 7/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.3579 - loss: 1.9956 - val_accuracy: 0.3111 - val_loss: 2.0389\n",
            "Epoch 8/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.3776 - loss: 1.9259 - val_accuracy: 0.3811 - val_loss: 1.9484\n",
            "Epoch 9/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.3933 - loss: 1.8759 - val_accuracy: 0.3283 - val_loss: 2.0291\n",
            "Epoch 10/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4109 - loss: 1.8406 - val_accuracy: 0.4122 - val_loss: 1.8818\n",
            "Epoch 11/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4236 - loss: 1.7950 - val_accuracy: 0.3606 - val_loss: 1.9437\n",
            "Epoch 12/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4317 - loss: 1.7641 - val_accuracy: 0.4467 - val_loss: 1.8078\n",
            "Epoch 13/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4447 - loss: 1.7223 - val_accuracy: 0.3756 - val_loss: 1.8845\n",
            "Epoch 14/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.4406 - loss: 1.7267 - val_accuracy: 0.4311 - val_loss: 1.7764\n",
            "Epoch 15/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4697 - loss: 1.6620 - val_accuracy: 0.4622 - val_loss: 1.7375\n",
            "Epoch 16/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 94ms/step - accuracy: 0.4735 - loss: 1.6453 - val_accuracy: 0.3794 - val_loss: 1.8845\n",
            "Epoch 17/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4684 - loss: 1.6418 - val_accuracy: 0.3789 - val_loss: 1.8784\n",
            "Epoch 18/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 95ms/step - accuracy: 0.4832 - loss: 1.5951 - val_accuracy: 0.3722 - val_loss: 1.9161\n",
            "Epoch 19/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4883 - loss: 1.6004 - val_accuracy: 0.4311 - val_loss: 1.8022\n",
            "Epoch 20/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.5027 - loss: 1.5814 - val_accuracy: 0.3283 - val_loss: 2.0505\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 15.\n",
            "\n",
            "Entrenamiento número 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_17', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 93ms/step - accuracy: 0.0981 - loss: 2.4976 - val_accuracy: 0.0978 - val_loss: 2.4613\n",
            "Epoch 2/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 95ms/step - accuracy: 0.1591 - loss: 2.4237 - val_accuracy: 0.2506 - val_loss: 2.3581\n",
            "Epoch 3/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.2175 - loss: 2.3286 - val_accuracy: 0.2422 - val_loss: 2.2682\n",
            "Epoch 4/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.2703 - loss: 2.2214 - val_accuracy: 0.2194 - val_loss: 2.1900\n",
            "Epoch 5/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.3096 - loss: 2.1226 - val_accuracy: 0.3511 - val_loss: 2.0736\n",
            "Epoch 6/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.3470 - loss: 2.0356 - val_accuracy: 0.2900 - val_loss: 2.0880\n",
            "Epoch 7/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.3610 - loss: 1.9635 - val_accuracy: 0.2950 - val_loss: 2.0375\n",
            "Epoch 8/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.3793 - loss: 1.9171 - val_accuracy: 0.2733 - val_loss: 2.1196\n",
            "Epoch 9/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 96ms/step - accuracy: 0.4000 - loss: 1.8681 - val_accuracy: 0.4228 - val_loss: 1.8611\n",
            "Epoch 10/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.4201 - loss: 1.8244 - val_accuracy: 0.4078 - val_loss: 1.8748\n",
            "Epoch 11/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.4211 - loss: 1.8054 - val_accuracy: 0.2594 - val_loss: 2.2256\n",
            "Epoch 12/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4315 - loss: 1.7611 - val_accuracy: 0.4067 - val_loss: 1.8618\n",
            "Epoch 13/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4390 - loss: 1.7458 - val_accuracy: 0.4211 - val_loss: 1.8081\n",
            "Epoch 14/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4518 - loss: 1.6964 - val_accuracy: 0.4083 - val_loss: 1.8170\n",
            "Epoch 15/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4560 - loss: 1.6804 - val_accuracy: 0.3689 - val_loss: 1.8974\n",
            "Epoch 16/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4693 - loss: 1.6415 - val_accuracy: 0.4128 - val_loss: 1.8204\n",
            "Epoch 17/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4663 - loss: 1.6424 - val_accuracy: 0.3406 - val_loss: 1.9897\n",
            "Epoch 18/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4784 - loss: 1.6045 - val_accuracy: 0.3906 - val_loss: 1.8546\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "\n",
            "Entrenamiento número 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_18', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 90ms/step - accuracy: 0.0891 - loss: 2.5011 - val_accuracy: 0.1800 - val_loss: 2.4382\n",
            "Epoch 2/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.1526 - loss: 2.4264 - val_accuracy: 0.2039 - val_loss: 2.3532\n",
            "Epoch 3/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.2348 - loss: 2.3260 - val_accuracy: 0.2028 - val_loss: 2.2882\n",
            "Epoch 4/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.2837 - loss: 2.2235 - val_accuracy: 0.2500 - val_loss: 2.2489\n",
            "Epoch 5/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.3147 - loss: 2.1211 - val_accuracy: 0.2461 - val_loss: 2.1210\n",
            "Epoch 6/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 92ms/step - accuracy: 0.3486 - loss: 2.0275 - val_accuracy: 0.3489 - val_loss: 2.0138\n",
            "Epoch 7/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.3583 - loss: 1.9682 - val_accuracy: 0.3844 - val_loss: 1.9594\n",
            "Epoch 8/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.3722 - loss: 1.9164 - val_accuracy: 0.3439 - val_loss: 1.9562\n",
            "Epoch 9/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.3799 - loss: 1.8802 - val_accuracy: 0.3939 - val_loss: 1.9037\n",
            "Epoch 10/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4176 - loss: 1.8330 - val_accuracy: 0.3933 - val_loss: 1.8855\n",
            "Epoch 11/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4212 - loss: 1.7959 - val_accuracy: 0.4106 - val_loss: 1.8595\n",
            "Epoch 12/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4355 - loss: 1.7488 - val_accuracy: 0.3894 - val_loss: 1.8691\n",
            "Epoch 13/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4411 - loss: 1.7348 - val_accuracy: 0.3656 - val_loss: 1.9081\n",
            "Epoch 14/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4427 - loss: 1.7199 - val_accuracy: 0.3894 - val_loss: 1.8948\n",
            "Epoch 15/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4624 - loss: 1.6759 - val_accuracy: 0.4206 - val_loss: 1.8386\n",
            "Epoch 16/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4717 - loss: 1.6407 - val_accuracy: 0.3806 - val_loss: 1.9317\n",
            "Epoch 17/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.4752 - loss: 1.6400 - val_accuracy: 0.2267 - val_loss: 2.3196\n",
            "Epoch 18/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4831 - loss: 1.6185 - val_accuracy: 0.3817 - val_loss: 1.8577\n",
            "Epoch 19/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4836 - loss: 1.6044 - val_accuracy: 0.3878 - val_loss: 1.8811\n",
            "Epoch 20/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4969 - loss: 1.5773 - val_accuracy: 0.4456 - val_loss: 1.7517\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "\n",
            "Entrenamiento número 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_19', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 93ms/step - accuracy: 0.0969 - loss: 2.4981 - val_accuracy: 0.1111 - val_loss: 2.4492\n",
            "Epoch 2/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.1584 - loss: 2.4207 - val_accuracy: 0.1344 - val_loss: 2.3737\n",
            "Epoch 3/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.2237 - loss: 2.3201 - val_accuracy: 0.2378 - val_loss: 2.2431\n",
            "Epoch 4/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.2811 - loss: 2.2045 - val_accuracy: 0.3383 - val_loss: 2.1406\n",
            "Epoch 5/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.3230 - loss: 2.1128 - val_accuracy: 0.3483 - val_loss: 2.0755\n",
            "Epoch 6/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.3531 - loss: 2.0227 - val_accuracy: 0.2983 - val_loss: 2.1445\n",
            "Epoch 7/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.3629 - loss: 1.9815 - val_accuracy: 0.3900 - val_loss: 1.9851\n",
            "Epoch 8/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.3823 - loss: 1.9112 - val_accuracy: 0.3489 - val_loss: 1.9742\n",
            "Epoch 9/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.3937 - loss: 1.8689 - val_accuracy: 0.3644 - val_loss: 1.9656\n",
            "Epoch 10/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4121 - loss: 1.8310 - val_accuracy: 0.3278 - val_loss: 1.9631\n",
            "Epoch 11/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4283 - loss: 1.7866 - val_accuracy: 0.3878 - val_loss: 1.8723\n",
            "Epoch 12/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4254 - loss: 1.7532 - val_accuracy: 0.3822 - val_loss: 1.9076\n",
            "Epoch 13/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4460 - loss: 1.7332 - val_accuracy: 0.3350 - val_loss: 1.9910\n",
            "Epoch 14/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.4538 - loss: 1.6939 - val_accuracy: 0.3867 - val_loss: 1.9117\n",
            "Epoch 15/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4601 - loss: 1.6870 - val_accuracy: 0.3928 - val_loss: 1.8894\n",
            "Epoch 16/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4658 - loss: 1.6685 - val_accuracy: 0.4267 - val_loss: 1.7975\n",
            "Epoch 17/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.4845 - loss: 1.6289 - val_accuracy: 0.3817 - val_loss: 1.8991\n",
            "Epoch 18/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4764 - loss: 1.6093 - val_accuracy: 0.4422 - val_loss: 1.7545\n",
            "Epoch 19/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.4920 - loss: 1.5733 - val_accuracy: 0.4894 - val_loss: 1.6646\n",
            "Epoch 20/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4973 - loss: 1.5905 - val_accuracy: 0.4178 - val_loss: 1.8320\n",
            "Restoring model weights from the end of the best epoch: 19.\n",
            "\n",
            "Entrenamiento número 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_20', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 91ms/step - accuracy: 0.0992 - loss: 2.4955 - val_accuracy: 0.1311 - val_loss: 2.4486\n",
            "Epoch 2/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.1423 - loss: 2.4345 - val_accuracy: 0.2056 - val_loss: 2.3673\n",
            "Epoch 3/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.2301 - loss: 2.3380 - val_accuracy: 0.2439 - val_loss: 2.2923\n",
            "Epoch 4/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.2773 - loss: 2.2319 - val_accuracy: 0.3311 - val_loss: 2.1626\n",
            "Epoch 5/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.3108 - loss: 2.1357 - val_accuracy: 0.3517 - val_loss: 2.1327\n",
            "Epoch 6/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.3374 - loss: 2.0524 - val_accuracy: 0.3594 - val_loss: 2.0325\n",
            "Epoch 7/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.3629 - loss: 1.9776 - val_accuracy: 0.2694 - val_loss: 2.1245\n",
            "Epoch 8/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.3790 - loss: 1.9282 - val_accuracy: 0.3722 - val_loss: 1.9790\n",
            "Epoch 9/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.3992 - loss: 1.8762 - val_accuracy: 0.4339 - val_loss: 1.8491\n",
            "Epoch 10/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.4214 - loss: 1.8137 - val_accuracy: 0.3189 - val_loss: 2.0730\n",
            "Epoch 11/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4136 - loss: 1.8051 - val_accuracy: 0.3694 - val_loss: 1.8720\n",
            "Epoch 12/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.4323 - loss: 1.7685 - val_accuracy: 0.3506 - val_loss: 1.9153\n",
            "Epoch 13/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4419 - loss: 1.7410 - val_accuracy: 0.3450 - val_loss: 1.9974\n",
            "Epoch 14/20\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.4557 - loss: 1.6778 - val_accuracy: 0.3922 - val_loss: 1.8564\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n"
          ]
        }
      ],
      "source": [
        "# Modelo 1 - QuickDraw-Animals\n",
        "# Detalles:\n",
        "# Activacion: tanh\n",
        "# Perdida: categorical_hinge\n",
        "# Capas: 2\n",
        "# Epocas: 60\n",
        "# Batch size: 550\n",
        "\n",
        "acc_total_4, acc_clase_4, cm_4 = experiment(\n",
        "        train_images_animals,\n",
        "        train_labels_animals,\n",
        "        val_images_animals,\n",
        "        val_labels_animals,\n",
        "        test_images_animals,\n",
        "        test_labels_animals,\n",
        "        layers_size=[512,256],\n",
        "        n_classes=12,\n",
        "        activation='sigmoid',\n",
        "        loss_fn='categorical_crossentropy',\n",
        "        class_names=clases,\n",
        "        epochs=20,\n",
        "        batch_size=32,\n",
        "        n_experiments=5\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'sheep': 0.445,\n",
              "  'bear': 0.275,\n",
              "  'bee': 0.725,\n",
              "  'cat': 0.295,\n",
              "  'camel': 0.355,\n",
              "  'cow': 0.36,\n",
              "  'crab': 0.465,\n",
              "  'crocodile': 0.74,\n",
              "  'duck': 0.19,\n",
              "  'elephant': 0.61,\n",
              "  'dog': 0.015,\n",
              "  'giraffe': 0.8341708542713567},\n",
              " {'sheep': 0.81,\n",
              "  'bear': 0.205,\n",
              "  'bee': 0.48,\n",
              "  'cat': 0.125,\n",
              "  'camel': 0.375,\n",
              "  'cow': 0.38,\n",
              "  'crab': 0.585,\n",
              "  'crocodile': 0.6,\n",
              "  'duck': 0.16,\n",
              "  'elephant': 0.185,\n",
              "  'dog': 0.015,\n",
              "  'giraffe': 0.8944723618090452},\n",
              " {'sheep': 0.535,\n",
              "  'bear': 0.16,\n",
              "  'bee': 0.365,\n",
              "  'cat': 0.275,\n",
              "  'camel': 0.67,\n",
              "  'cow': 0.53,\n",
              "  'crab': 0.345,\n",
              "  'crocodile': 0.73,\n",
              "  'duck': 0.15,\n",
              "  'elephant': 0.16,\n",
              "  'dog': 0.12,\n",
              "  'giraffe': 0.8894472361809045},\n",
              " {'sheep': 0.52,\n",
              "  'bear': 0.395,\n",
              "  'bee': 0.545,\n",
              "  'cat': 0.38,\n",
              "  'camel': 0.525,\n",
              "  'cow': 0.37,\n",
              "  'crab': 0.575,\n",
              "  'crocodile': 0.67,\n",
              "  'duck': 0.21,\n",
              "  'elephant': 0.51,\n",
              "  'dog': 0.055,\n",
              "  'giraffe': 0.8743718592964824},\n",
              " {'sheep': 0.515,\n",
              "  'bear': 0.49,\n",
              "  'bee': 0.715,\n",
              "  'cat': 0.25,\n",
              "  'camel': 0.315,\n",
              "  'cow': 0.43,\n",
              "  'crab': 0.49,\n",
              "  'crocodile': 0.71,\n",
              "  'duck': 0.12,\n",
              "  'elephant': 0.11,\n",
              "  'dog': 0.07,\n",
              "  'giraffe': 0.8090452261306532}]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc_clase_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.44226761150479366,\n",
              " 0.40100041684035015,\n",
              " 0.4105877448937057,\n",
              " 0.46894539391413087,\n",
              " 0.4185077115464777]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc_total_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[ 89,   5,   3,   2,  15,  32,  11,   6,   4,  30,   3,   0],\n",
              "        [ 16,  55,  18,  13,  10,   8,   9,   5,   8,  46,   2,  10],\n",
              "        [  0,   1, 145,   3,   0,  22,   6,   8,   1,  12,   0,   2],\n",
              "        [  1,  11,  38,  59,  13,  19,  20,  15,   2,  20,   0,   2],\n",
              "        [  9,   4,   8,   6,  71,   9,  18,  12,   5,  49,   2,   7],\n",
              "        [ 13,   3,  36,   3,   8,  72,  17,  10,   1,  33,   2,   2],\n",
              "        [  4,   1,  16,  10,   3,  16,  93,  39,   1,  15,   0,   2],\n",
              "        [  1,   0,   9,   1,   3,   4,  14, 148,   2,  18,   0,   0],\n",
              "        [  3,   8,  18,   3,  24,   8,   8,  13,  38,  64,   2,  11],\n",
              "        [  4,   6,  27,   1,   4,  10,   5,  15,   3, 122,   0,   3],\n",
              "        [  7,   6,  17,   6,   8,  25,  28,  34,   4,  59,   3,   3],\n",
              "        [  0,   0,  12,   6,   3,   0,   4,   1,   4,   3,   0, 166]]),\n",
              " array([[162,   0,   2,   0,   7,  11,   9,   2,   4,   1,   0,   2],\n",
              "        [ 59,  41,   6,   3,  23,  10,  12,   1,  14,   3,   2,  26],\n",
              "        [  6,   1,  96,   1,   3,  51,  18,   3,   4,   1,   2,  14],\n",
              "        [ 28,  12,  17,  25,  27,  29,  41,   5,   3,   0,   1,  12],\n",
              "        [ 61,   2,   3,   0,  75,   7,  23,   1,   5,   1,   6,  16],\n",
              "        [ 55,   1,  12,   2,  11,  76,  29,   4,   1,   0,   4,   5],\n",
              "        [ 34,   1,   6,   0,   4,  12, 117,  15,   1,   0,   0,  10],\n",
              "        [ 14,   0,   5,   0,   9,   3,  46, 120,   2,   0,   0,   1],\n",
              "        [ 37,   4,  10,   2,  49,   6,  23,   3,  32,   1,   8,  25],\n",
              "        [ 55,   6,  15,   1,  14,  22,  17,  10,   9,  37,   4,  10],\n",
              "        [ 52,   5,   5,   2,  16,  31,  52,   9,   8,   7,   3,  10],\n",
              "        [  1,   1,   4,   0,   8,   0,   6,   0,   1,   0,   0, 178]]),\n",
              " array([[107,   0,   2,   2,  50,  23,   1,   5,   3,   0,   6,   1],\n",
              "        [ 19,  32,   5,  14,  58,  14,   3,   5,  19,   3,   9,  19],\n",
              "        [  2,   1,  73,   8,   7,  63,   8,   8,   4,   4,   8,  14],\n",
              "        [  8,   5,  11,  55,  42,  35,  13,  13,   3,   0,   6,   9],\n",
              "        [  8,   1,   2,   1, 134,  15,   7,   4,   3,   1,  12,  12],\n",
              "        [ 22,   2,   6,   5,  25, 106,   8,  15,   1,   0,   7,   3],\n",
              "        [  9,   1,   5,   9,  21,  34,  69,  37,   1,   2,   5,   7],\n",
              "        [  1,   0,   1,   1,  20,  12,   7, 146,   2,   0,   9,   1],\n",
              "        [  2,   2,   5,   4,  88,  10,   4,  12,  30,   0,  18,  25],\n",
              "        [ 17,   5,   5,   4,  42,  30,   2,  24,   8,  32,  20,  11],\n",
              "        [ 14,   3,   5,   7,  46,  45,  13,  24,   5,   7,  24,   7],\n",
              "        [  0,   1,   3,   0,  13,   2,   2,   0,   1,   0,   0, 177]]),\n",
              " array([[104,   8,   2,   2,  25,  21,  13,   3,   5,  10,   7,   0],\n",
              "        [ 19,  79,   8,   8,  23,   7,  11,   2,  10,  18,   4,  11],\n",
              "        [  2,   2, 109,  13,   2,  29,   9,   5,   4,  14,   4,   7],\n",
              "        [  2,  14,  23,  76,  21,  10,  29,   8,   1,   8,   4,   4],\n",
              "        [ 10,   5,   2,   8, 105,   7,  21,   4,   2,  18,   6,  12],\n",
              "        [ 19,   3,  16,  12,  15,  74,  29,   6,   2,  14,   7,   3],\n",
              "        [  6,   2,   7,  15,  11,  10, 115,  19,   2,   9,   1,   3],\n",
              "        [  1,   0,   6,   2,  13,   1,  28, 134,   3,   8,   3,   1],\n",
              "        [  0,  12,  13,   6,  55,   4,  14,   5,  42,  25,   6,  18],\n",
              "        [  7,  10,  12,   9,  13,  14,  12,  11,   3, 102,   1,   6],\n",
              "        [ 12,   6,  11,  12,  24,  23,  39,  14,   7,  37,  11,   4],\n",
              "        [  0,   2,   6,   0,   8,   0,   5,   0,   4,   0,   0, 174]]),\n",
              " array([[103,  26,   4,   3,  10,  29,   9,   4,   3,   0,   8,   1],\n",
              "        [ 17,  98,  17,   8,   9,  10,   9,   3,   2,   2,  13,  12],\n",
              "        [  3,   3, 143,   8,   0,  24,   8,   6,   1,   0,   2,   2],\n",
              "        [  5,  39,  37,  50,  10,  20,  18,  13,   1,   0,   2,   5],\n",
              "        [ 17,  22,   7,  23,  63,  15,  21,   6,   3,   1,  14,   8],\n",
              "        [ 19,   8,  32,   8,   9,  86,  15,  14,   0,   0,   7,   2],\n",
              "        [  6,   3,  14,  18,   3,  16,  98,  33,   0,   0,   5,   4],\n",
              "        [  1,   0,  10,   8,   5,   4,  21, 142,   1,   0,   7,   1],\n",
              "        [  6,  44,  28,  15,  19,   8,  10,  10,  24,   0,  19,  17],\n",
              "        [ 12,  21,  43,  12,   7,  28,  12,  16,   5,  22,  15,   7],\n",
              "        [ 14,  19,  20,  16,  11,  40,  33,  23,   3,   3,  14,   4],\n",
              "        [  0,   4,  10,  15,   4,   1,   2,   0,   2,   0,   0, 161]])]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cm_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "fekRLfs0Jj4L"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entrenamiento número 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_21', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 166ms/step - accuracy: 0.0864 - loss: 1.1001 - val_accuracy: 0.1056 - val_loss: 1.0240\n",
            "Epoch 2/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - accuracy: 0.0893 - loss: 1.0221 - val_accuracy: 0.0828 - val_loss: 1.0177\n",
            "Epoch 3/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - accuracy: 0.0953 - loss: 1.0160 - val_accuracy: 0.0989 - val_loss: 1.0104\n",
            "Epoch 4/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.0981 - loss: 1.0095 - val_accuracy: 0.0961 - val_loss: 1.0088\n",
            "Epoch 5/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.1059 - loss: 1.0083 - val_accuracy: 0.1117 - val_loss: 1.0069\n",
            "Epoch 6/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1047 - loss: 1.0066 - val_accuracy: 0.1056 - val_loss: 1.0044\n",
            "Epoch 7/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.1076 - loss: 1.0038 - val_accuracy: 0.1056 - val_loss: 1.0012\n",
            "Epoch 8/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.1150 - loss: 1.0009 - val_accuracy: 0.1078 - val_loss: 1.0005\n",
            "Epoch 9/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.1181 - loss: 1.0005 - val_accuracy: 0.1161 - val_loss: 1.0006\n",
            "Epoch 10/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1153 - loss: 1.0005 - val_accuracy: 0.1022 - val_loss: 1.0006\n",
            "Epoch 11/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1310 - loss: 1.0005 - val_accuracy: 0.1172 - val_loss: 1.0005\n",
            "Epoch 12/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1225 - loss: 1.0005 - val_accuracy: 0.1156 - val_loss: 1.0005\n",
            "Epoch 13/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - accuracy: 0.1323 - loss: 1.0005 - val_accuracy: 0.1250 - val_loss: 1.0006\n",
            "Epoch 14/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1286 - loss: 1.0005 - val_accuracy: 0.1422 - val_loss: 1.0005\n",
            "Epoch 15/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.1331 - loss: 1.0005 - val_accuracy: 0.1283 - val_loss: 1.0005\n",
            "Epoch 16/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - accuracy: 0.1502 - loss: 1.0005 - val_accuracy: 0.1250 - val_loss: 1.0005\n",
            "Epoch 17/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.1474 - loss: 1.0004 - val_accuracy: 0.1278 - val_loss: 1.0005\n",
            "Epoch 18/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - accuracy: 0.1524 - loss: 1.0004 - val_accuracy: 0.1406 - val_loss: 1.0005\n",
            "Epoch 19/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1556 - loss: 1.0004 - val_accuracy: 0.1600 - val_loss: 1.0004\n",
            "Epoch 20/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.1528 - loss: 1.0004 - val_accuracy: 0.1328 - val_loss: 1.0005\n",
            "Epoch 21/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.1598 - loss: 1.0004 - val_accuracy: 0.1333 - val_loss: 1.0004\n",
            "Epoch 22/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.1589 - loss: 1.0004 - val_accuracy: 0.1500 - val_loss: 1.0005\n",
            "Epoch 23/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1681 - loss: 1.0004 - val_accuracy: 0.1500 - val_loss: 1.0004\n",
            "Epoch 24/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1730 - loss: 1.0004 - val_accuracy: 0.1572 - val_loss: 1.0004\n",
            "Epoch 25/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - accuracy: 0.1734 - loss: 1.0004 - val_accuracy: 0.1411 - val_loss: 1.0004\n",
            "Epoch 26/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 166ms/step - accuracy: 0.1755 - loss: 1.0004 - val_accuracy: 0.1494 - val_loss: 1.0005\n",
            "Epoch 27/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 168ms/step - accuracy: 0.1841 - loss: 1.0004 - val_accuracy: 0.1550 - val_loss: 1.0004\n",
            "Epoch 28/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1860 - loss: 1.0004 - val_accuracy: 0.1600 - val_loss: 1.0004\n",
            "Epoch 29/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - accuracy: 0.1895 - loss: 1.0004 - val_accuracy: 0.1728 - val_loss: 1.0004\n",
            "Epoch 30/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 171ms/step - accuracy: 0.1992 - loss: 1.0003 - val_accuracy: 0.1744 - val_loss: 1.0004\n",
            "Epoch 31/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - accuracy: 0.1922 - loss: 1.0004 - val_accuracy: 0.1556 - val_loss: 1.0004\n",
            "Epoch 32/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.1940 - loss: 1.0004 - val_accuracy: 0.1667 - val_loss: 1.0004\n",
            "Epoch 33/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 166ms/step - accuracy: 0.2021 - loss: 1.0003 - val_accuracy: 0.1900 - val_loss: 1.0004\n",
            "Epoch 34/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.2021 - loss: 1.0003 - val_accuracy: 0.1767 - val_loss: 1.0004\n",
            "Epoch 35/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - accuracy: 0.1989 - loss: 1.0003 - val_accuracy: 0.1967 - val_loss: 1.0004\n",
            "Epoch 36/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 165ms/step - accuracy: 0.2050 - loss: 1.0003 - val_accuracy: 0.2044 - val_loss: 1.0004\n",
            "Epoch 37/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.2098 - loss: 1.0003 - val_accuracy: 0.1728 - val_loss: 1.0004\n",
            "Epoch 38/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - accuracy: 0.2091 - loss: 1.0003 - val_accuracy: 0.1761 - val_loss: 1.0004\n",
            "Epoch 39/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - accuracy: 0.2084 - loss: 1.0003 - val_accuracy: 0.2000 - val_loss: 1.0003\n",
            "Epoch 40/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.2150 - loss: 1.0003 - val_accuracy: 0.1561 - val_loss: 1.0005\n",
            "Epoch 41/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.2258 - loss: 1.0003 - val_accuracy: 0.1906 - val_loss: 1.0004\n",
            "Epoch 42/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.2194 - loss: 1.0003 - val_accuracy: 0.2178 - val_loss: 1.0003\n",
            "Epoch 43/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 170ms/step - accuracy: 0.2173 - loss: 1.0003 - val_accuracy: 0.1506 - val_loss: 1.0004\n",
            "Epoch 44/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.2253 - loss: 1.0003 - val_accuracy: 0.2056 - val_loss: 1.0003\n",
            "Epoch 45/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.2291 - loss: 1.0003 - val_accuracy: 0.2017 - val_loss: 1.0003\n",
            "Epoch 46/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - accuracy: 0.2126 - loss: 1.0003 - val_accuracy: 0.1761 - val_loss: 1.0004\n",
            "Epoch 47/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.2116 - loss: 1.0003 - val_accuracy: 0.2144 - val_loss: 1.0003\n",
            "Epoch 47: early stopping\n",
            "Restoring model weights from the end of the best epoch: 42.\n",
            "\n",
            "Entrenamiento número 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_22', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 166ms/step - accuracy: 0.0823 - loss: 1.0369 - val_accuracy: 0.0961 - val_loss: 1.0140\n",
            "Epoch 2/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.1002 - loss: 1.0119 - val_accuracy: 0.1006 - val_loss: 1.0069\n",
            "Epoch 3/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 166ms/step - accuracy: 0.1070 - loss: 1.0061 - val_accuracy: 0.1189 - val_loss: 1.0036\n",
            "Epoch 4/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1149 - loss: 1.0026 - val_accuracy: 0.1133 - val_loss: 1.0006\n",
            "Epoch 5/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - accuracy: 0.1161 - loss: 1.0006 - val_accuracy: 0.1250 - val_loss: 1.0007\n",
            "Epoch 6/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.1179 - loss: 1.0006 - val_accuracy: 0.1222 - val_loss: 1.0006\n",
            "Epoch 7/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.1271 - loss: 1.0006 - val_accuracy: 0.1161 - val_loss: 1.0006\n",
            "Epoch 8/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 166ms/step - accuracy: 0.1318 - loss: 1.0006 - val_accuracy: 0.1306 - val_loss: 1.0006\n",
            "Epoch 9/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.1261 - loss: 1.0006 - val_accuracy: 0.1211 - val_loss: 1.0006\n",
            "Epoch 10/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - accuracy: 0.1295 - loss: 1.0006 - val_accuracy: 0.1450 - val_loss: 1.0006\n",
            "Epoch 11/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 169ms/step - accuracy: 0.1503 - loss: 1.0005 - val_accuracy: 0.1300 - val_loss: 1.0006\n",
            "Epoch 12/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1431 - loss: 1.0006 - val_accuracy: 0.1394 - val_loss: 1.0005\n",
            "Epoch 13/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - accuracy: 0.1464 - loss: 1.0005 - val_accuracy: 0.1389 - val_loss: 1.0005\n",
            "Epoch 14/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - accuracy: 0.1513 - loss: 1.0005 - val_accuracy: 0.1517 - val_loss: 1.0005\n",
            "Epoch 15/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.1588 - loss: 1.0005 - val_accuracy: 0.1483 - val_loss: 1.0005\n",
            "Epoch 16/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1569 - loss: 1.0005 - val_accuracy: 0.1483 - val_loss: 1.0005\n",
            "Epoch 17/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.1635 - loss: 1.0005 - val_accuracy: 0.1528 - val_loss: 1.0006\n",
            "Epoch 18/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.1624 - loss: 1.0005 - val_accuracy: 0.1656 - val_loss: 1.0006\n",
            "Epoch 19/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - accuracy: 0.1613 - loss: 1.0005 - val_accuracy: 0.1544 - val_loss: 1.0005\n",
            "Epoch 20/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1719 - loss: 1.0005 - val_accuracy: 0.1489 - val_loss: 1.0005\n",
            "Epoch 21/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.1751 - loss: 1.0005 - val_accuracy: 0.1700 - val_loss: 1.0004\n",
            "Epoch 22/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 165ms/step - accuracy: 0.1776 - loss: 1.0004 - val_accuracy: 0.1678 - val_loss: 1.0005\n",
            "Epoch 23/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.1723 - loss: 1.0004 - val_accuracy: 0.1694 - val_loss: 1.0005\n",
            "Epoch 24/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1834 - loss: 1.0004 - val_accuracy: 0.1672 - val_loss: 1.0004\n",
            "Epoch 25/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - accuracy: 0.1916 - loss: 1.0004 - val_accuracy: 0.1550 - val_loss: 1.0005\n",
            "Epoch 26/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.1869 - loss: 1.0004 - val_accuracy: 0.1678 - val_loss: 1.0004\n",
            "Epoch 27/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1840 - loss: 1.0004 - val_accuracy: 0.1611 - val_loss: 1.0004\n",
            "Epoch 28/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - accuracy: 0.1915 - loss: 1.0004 - val_accuracy: 0.2011 - val_loss: 1.0004\n",
            "Epoch 29/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.1995 - loss: 1.0004 - val_accuracy: 0.2050 - val_loss: 1.0004\n",
            "Epoch 30/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.2023 - loss: 1.0004 - val_accuracy: 0.1872 - val_loss: 1.0004\n",
            "Epoch 31/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1993 - loss: 1.0004 - val_accuracy: 0.2067 - val_loss: 1.0005\n",
            "Epoch 32/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.2043 - loss: 1.0004 - val_accuracy: 0.1989 - val_loss: 1.0004\n",
            "Epoch 33/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.2170 - loss: 1.0004 - val_accuracy: 0.2144 - val_loss: 1.0004\n",
            "Epoch 34/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - accuracy: 0.2076 - loss: 1.0004 - val_accuracy: 0.2000 - val_loss: 1.0004\n",
            "Epoch 34: early stopping\n",
            "Restoring model weights from the end of the best epoch: 29.\n",
            "\n",
            "Entrenamiento número 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_23', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 161ms/step - accuracy: 0.0788 - loss: 1.0779 - val_accuracy: 0.0828 - val_loss: 1.0182\n",
            "Epoch 2/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.0766 - loss: 1.0179 - val_accuracy: 0.0822 - val_loss: 1.0157\n",
            "Epoch 3/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - accuracy: 0.0765 - loss: 1.0151 - val_accuracy: 0.0939 - val_loss: 1.0123\n",
            "Epoch 4/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.0853 - loss: 1.0113 - val_accuracy: 0.0900 - val_loss: 1.0083\n",
            "Epoch 5/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.0911 - loss: 1.0076 - val_accuracy: 0.0900 - val_loss: 1.0061\n",
            "Epoch 6/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.0874 - loss: 1.0055 - val_accuracy: 0.0972 - val_loss: 1.0045\n",
            "Epoch 7/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.0958 - loss: 1.0043 - val_accuracy: 0.1106 - val_loss: 1.0037\n",
            "Epoch 8/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.0948 - loss: 1.0035 - val_accuracy: 0.1178 - val_loss: 1.0028\n",
            "Epoch 9/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.0944 - loss: 1.0024 - val_accuracy: 0.0956 - val_loss: 1.0014\n",
            "Epoch 10/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.0984 - loss: 1.0009 - val_accuracy: 0.0983 - val_loss: 1.0006\n",
            "Epoch 11/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.0949 - loss: 1.0005 - val_accuracy: 0.1100 - val_loss: 1.0005\n",
            "Epoch 12/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - accuracy: 0.0994 - loss: 1.0005 - val_accuracy: 0.1111 - val_loss: 1.0006\n",
            "Epoch 13/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.1037 - loss: 1.0005 - val_accuracy: 0.1256 - val_loss: 1.0005\n",
            "Epoch 14/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.1087 - loss: 1.0005 - val_accuracy: 0.1178 - val_loss: 1.0006\n",
            "Epoch 15/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - accuracy: 0.1104 - loss: 1.0005 - val_accuracy: 0.1272 - val_loss: 1.0005\n",
            "Epoch 16/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1081 - loss: 1.0005 - val_accuracy: 0.1267 - val_loss: 1.0005\n",
            "Epoch 17/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1163 - loss: 1.0005 - val_accuracy: 0.1256 - val_loss: 1.0004\n",
            "Epoch 18/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1269 - loss: 1.0005 - val_accuracy: 0.1378 - val_loss: 1.0005\n",
            "Epoch 19/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.1296 - loss: 1.0004 - val_accuracy: 0.1350 - val_loss: 1.0005\n",
            "Epoch 20/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 155ms/step - accuracy: 0.1284 - loss: 1.0004 - val_accuracy: 0.1150 - val_loss: 1.0006\n",
            "Epoch 21/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.1305 - loss: 1.0004 - val_accuracy: 0.1428 - val_loss: 1.0005\n",
            "Epoch 22/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.1280 - loss: 1.0004 - val_accuracy: 0.1256 - val_loss: 1.0005\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 17.\n",
            "\n",
            "Entrenamiento número 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_24', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 163ms/step - accuracy: 0.0821 - loss: 1.0563 - val_accuracy: 0.0950 - val_loss: 1.0146\n",
            "Epoch 2/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.0917 - loss: 1.0125 - val_accuracy: 0.0967 - val_loss: 1.0093\n",
            "Epoch 3/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - accuracy: 0.0918 - loss: 1.0081 - val_accuracy: 0.0883 - val_loss: 1.0042\n",
            "Epoch 4/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.1011 - loss: 1.0034 - val_accuracy: 0.0939 - val_loss: 1.0012\n",
            "Epoch 5/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1004 - loss: 1.0008 - val_accuracy: 0.1033 - val_loss: 1.0007\n",
            "Epoch 6/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.0979 - loss: 1.0006 - val_accuracy: 0.1172 - val_loss: 1.0006\n",
            "Epoch 7/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1022 - loss: 1.0006 - val_accuracy: 0.1156 - val_loss: 1.0006\n",
            "Epoch 8/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 155ms/step - accuracy: 0.1075 - loss: 1.0006 - val_accuracy: 0.1244 - val_loss: 1.0006\n",
            "Epoch 9/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.1058 - loss: 1.0006 - val_accuracy: 0.1317 - val_loss: 1.0005\n",
            "Epoch 10/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 155ms/step - accuracy: 0.1166 - loss: 1.0005 - val_accuracy: 0.1239 - val_loss: 1.0005\n",
            "Epoch 11/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1153 - loss: 1.0005 - val_accuracy: 0.1356 - val_loss: 1.0006\n",
            "Epoch 12/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1171 - loss: 1.0005 - val_accuracy: 0.1417 - val_loss: 1.0005\n",
            "Epoch 13/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.1318 - loss: 1.0005 - val_accuracy: 0.1411 - val_loss: 1.0005\n",
            "Epoch 14/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.1284 - loss: 1.0005 - val_accuracy: 0.1350 - val_loss: 1.0005\n",
            "Epoch 15/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.1397 - loss: 1.0005 - val_accuracy: 0.1294 - val_loss: 1.0005\n",
            "Epoch 16/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.1312 - loss: 1.0005 - val_accuracy: 0.1306 - val_loss: 1.0005\n",
            "Epoch 17/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.1377 - loss: 1.0005 - val_accuracy: 0.1489 - val_loss: 1.0004\n",
            "Epoch 18/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 166ms/step - accuracy: 0.1526 - loss: 1.0004 - val_accuracy: 0.1483 - val_loss: 1.0005\n",
            "Epoch 19/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.1480 - loss: 1.0004 - val_accuracy: 0.1628 - val_loss: 1.0005\n",
            "Epoch 20/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1477 - loss: 1.0005 - val_accuracy: 0.1628 - val_loss: 1.0005\n",
            "Epoch 21/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - accuracy: 0.1497 - loss: 1.0004 - val_accuracy: 0.1478 - val_loss: 1.0005\n",
            "Epoch 22/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1605 - loss: 1.0004 - val_accuracy: 0.1494 - val_loss: 1.0004\n",
            "Epoch 23/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.1639 - loss: 1.0004 - val_accuracy: 0.1667 - val_loss: 1.0004\n",
            "Epoch 24/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - accuracy: 0.1658 - loss: 1.0004 - val_accuracy: 0.1583 - val_loss: 1.0005\n",
            "Epoch 25/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.1561 - loss: 1.0004 - val_accuracy: 0.1667 - val_loss: 1.0004\n",
            "Epoch 26/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.1705 - loss: 1.0004 - val_accuracy: 0.1817 - val_loss: 1.0004\n",
            "Epoch 27/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1786 - loss: 1.0004 - val_accuracy: 0.1733 - val_loss: 1.0004\n",
            "Epoch 28/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.1738 - loss: 1.0004 - val_accuracy: 0.1639 - val_loss: 1.0004\n",
            "Epoch 29/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.1746 - loss: 1.0004 - val_accuracy: 0.1828 - val_loss: 1.0004\n",
            "Epoch 30/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - accuracy: 0.1834 - loss: 1.0004 - val_accuracy: 0.1956 - val_loss: 1.0004\n",
            "Epoch 31/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1828 - loss: 1.0004 - val_accuracy: 0.1667 - val_loss: 1.0004\n",
            "Epoch 32/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.1844 - loss: 1.0004 - val_accuracy: 0.1761 - val_loss: 1.0004\n",
            "Epoch 33/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - accuracy: 0.1945 - loss: 1.0004 - val_accuracy: 0.1833 - val_loss: 1.0004\n",
            "Epoch 34/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.1893 - loss: 1.0003 - val_accuracy: 0.1733 - val_loss: 1.0004\n",
            "Epoch 35/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1970 - loss: 1.0003 - val_accuracy: 0.1828 - val_loss: 1.0004\n",
            "Epoch 36/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1953 - loss: 1.0004 - val_accuracy: 0.1750 - val_loss: 1.0004\n",
            "Epoch 36: early stopping\n",
            "Restoring model weights from the end of the best epoch: 31.\n",
            "\n",
            "Entrenamiento número 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_25', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 167ms/step - accuracy: 0.0874 - loss: 1.0432 - val_accuracy: 0.0989 - val_loss: 1.0149\n",
            "Epoch 2/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.0816 - loss: 1.0123 - val_accuracy: 0.0828 - val_loss: 1.0058\n",
            "Epoch 3/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - accuracy: 0.0762 - loss: 1.0055 - val_accuracy: 0.0933 - val_loss: 1.0043\n",
            "Epoch 4/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.0862 - loss: 1.0040 - val_accuracy: 0.0961 - val_loss: 1.0034\n",
            "Epoch 5/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.0938 - loss: 1.0031 - val_accuracy: 0.0972 - val_loss: 1.0021\n",
            "Epoch 6/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 171ms/step - accuracy: 0.0953 - loss: 1.0016 - val_accuracy: 0.1122 - val_loss: 1.0007\n",
            "Epoch 7/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.0968 - loss: 1.0006 - val_accuracy: 0.1033 - val_loss: 1.0006\n",
            "Epoch 8/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 155ms/step - accuracy: 0.1021 - loss: 1.0006 - val_accuracy: 0.1033 - val_loss: 1.0006\n",
            "Epoch 9/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1066 - loss: 1.0006 - val_accuracy: 0.1200 - val_loss: 1.0006\n",
            "Epoch 10/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.1012 - loss: 1.0006 - val_accuracy: 0.1133 - val_loss: 1.0006\n",
            "Epoch 11/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.1076 - loss: 1.0006 - val_accuracy: 0.1189 - val_loss: 1.0006\n",
            "Epoch 12/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1098 - loss: 1.0006 - val_accuracy: 0.1244 - val_loss: 1.0005\n",
            "Epoch 13/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.1232 - loss: 1.0005 - val_accuracy: 0.1183 - val_loss: 1.0005\n",
            "Epoch 14/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 155ms/step - accuracy: 0.1211 - loss: 1.0005 - val_accuracy: 0.1250 - val_loss: 1.0006\n",
            "Epoch 15/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - accuracy: 0.1287 - loss: 1.0005 - val_accuracy: 0.1289 - val_loss: 1.0006\n",
            "Epoch 16/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.1274 - loss: 1.0005 - val_accuracy: 0.1239 - val_loss: 1.0005\n",
            "Epoch 17/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.1368 - loss: 1.0005 - val_accuracy: 0.1500 - val_loss: 1.0005\n",
            "Epoch 18/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1401 - loss: 1.0005 - val_accuracy: 0.1244 - val_loss: 1.0006\n",
            "Epoch 19/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.1393 - loss: 1.0005 - val_accuracy: 0.1283 - val_loss: 1.0005\n",
            "Epoch 20/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.1448 - loss: 1.0005 - val_accuracy: 0.1450 - val_loss: 1.0005\n",
            "Epoch 21/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.1473 - loss: 1.0005 - val_accuracy: 0.1483 - val_loss: 1.0004\n",
            "Epoch 22/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - accuracy: 0.1430 - loss: 1.0005 - val_accuracy: 0.1333 - val_loss: 1.0005\n",
            "Epoch 23/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.1626 - loss: 1.0004 - val_accuracy: 0.1489 - val_loss: 1.0005\n",
            "Epoch 24/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 155ms/step - accuracy: 0.1657 - loss: 1.0004 - val_accuracy: 0.1583 - val_loss: 1.0005\n",
            "Epoch 25/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.1616 - loss: 1.0004 - val_accuracy: 0.1622 - val_loss: 1.0004\n",
            "Epoch 26/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.1606 - loss: 1.0004 - val_accuracy: 0.1728 - val_loss: 1.0004\n",
            "Epoch 27/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 154ms/step - accuracy: 0.1751 - loss: 1.0004 - val_accuracy: 0.1667 - val_loss: 1.0004\n",
            "Epoch 28/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 155ms/step - accuracy: 0.1820 - loss: 1.0004 - val_accuracy: 0.1800 - val_loss: 1.0005\n",
            "Epoch 29/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1781 - loss: 1.0004 - val_accuracy: 0.1789 - val_loss: 1.0004\n",
            "Epoch 30/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - accuracy: 0.1777 - loss: 1.0004 - val_accuracy: 0.1567 - val_loss: 1.0005\n",
            "Epoch 31/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.1874 - loss: 1.0004 - val_accuracy: 0.1900 - val_loss: 1.0004\n",
            "Epoch 32/50\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.1857 - loss: 1.0004 - val_accuracy: 0.1361 - val_loss: 1.0005\n",
            "Epoch 32: early stopping\n",
            "Restoring model weights from the end of the best epoch: 27.\n"
          ]
        }
      ],
      "source": [
        "# Modelo 2 - QuickDraw-Animals\n",
        "# Detalles:\n",
        "# Activacion: tanh\n",
        "# Perdida: categorical_crossentropy\n",
        "# Capas: 2\n",
        "# Epocas: 10\n",
        "# Batch size: 1000\n",
        "\n",
        "acc_total_5, acc_clase_5, cm_5 = experiment(\n",
        "        train_images_animals,\n",
        "        train_labels_animals,\n",
        "        val_images_animals,\n",
        "        val_labels_animals,\n",
        "        test_images_animals,\n",
        "        test_labels_animals,\n",
        "        layers_size=[512, 256, 128],\n",
        "        n_classes=12,\n",
        "        activation='sigmoid',\n",
        "        loss_fn='categorical_hinge',\n",
        "        class_names=clases,\n",
        "        epochs=50,\n",
        "        batch_size=128,\n",
        "        n_experiments=5\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'sheep': 0.235,\n",
              "  'bear': 0.065,\n",
              "  'bee': 0.64,\n",
              "  'cat': 0.025,\n",
              "  'camel': 0.085,\n",
              "  'cow': 0.15,\n",
              "  'crab': 0.1,\n",
              "  'crocodile': 0.525,\n",
              "  'duck': 0.08,\n",
              "  'elephant': 0.225,\n",
              "  'dog': 0.025,\n",
              "  'giraffe': 0.45226130653266333},\n",
              " {'sheep': 0.27,\n",
              "  'bear': 0.19,\n",
              "  'bee': 0.335,\n",
              "  'cat': 0.025,\n",
              "  'camel': 0.255,\n",
              "  'cow': 0.03,\n",
              "  'crab': 0.05,\n",
              "  'crocodile': 0.51,\n",
              "  'duck': 0.02,\n",
              "  'elephant': 0.185,\n",
              "  'dog': 0.07,\n",
              "  'giraffe': 0.36683417085427134},\n",
              " {'sheep': 0.1,\n",
              "  'bear': 0.23,\n",
              "  'bee': 0.02,\n",
              "  'cat': 0.01,\n",
              "  'camel': 0.12,\n",
              "  'cow': 0.135,\n",
              "  'crab': 0.03,\n",
              "  'crocodile': 0.105,\n",
              "  'duck': 0.25,\n",
              "  'elephant': 0.075,\n",
              "  'dog': 0.03,\n",
              "  'giraffe': 0.18592964824120603},\n",
              " {'sheep': 0.15,\n",
              "  'bear': 0.15,\n",
              "  'bee': 0.325,\n",
              "  'cat': 0.08,\n",
              "  'camel': 0.325,\n",
              "  'cow': 0.155,\n",
              "  'crab': 0.06,\n",
              "  'crocodile': 0.22,\n",
              "  'duck': 0.075,\n",
              "  'elephant': 0.06,\n",
              "  'dog': 0.085,\n",
              "  'giraffe': 0.16080402010050251},\n",
              " {'sheep': 0.085,\n",
              "  'bear': 0.19,\n",
              "  'bee': 0.15,\n",
              "  'cat': 0.17,\n",
              "  'camel': 0.035,\n",
              "  'cow': 0.26,\n",
              "  'crab': 0.065,\n",
              "  'crocodile': 0.405,\n",
              "  'duck': 0.1,\n",
              "  'elephant': 0.055,\n",
              "  'dog': 0.025,\n",
              "  'giraffe': 0.36683417085427134}]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc_clase_5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.21717382242601083,\n",
              " 0.19216340141725718,\n",
              " 0.10754481033764068,\n",
              " 0.15381408920383494,\n",
              " 0.15881617340558565]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc_total_5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[ 47,   2,  38,   0,  23,  25,   4,   9,   5,  34,   1,  12],\n",
              "        [ 20,  13,  50,   1,  21,  19,   3,   1,  13,  29,   2,  28],\n",
              "        [  6,   1, 128,   0,   5,  14,   3,   9,   5,  21,   2,   6],\n",
              "        [ 19,  10,  66,   5,  10,  19,   6,  11,   9,  32,   6,   7],\n",
              "        [ 31,   3,  26,   0,  17,  20,   7,  16,  20,  33,   1,  26],\n",
              "        [ 20,   2,  67,   0,  14,  30,   5,  16,   3,  31,   3,   9],\n",
              "        [ 21,   2,  44,   0,  15,  25,  20,  29,   9,  27,   2,   6],\n",
              "        [  8,   1,  30,   0,   8,   5,   3, 105,   8,  18,   1,  13],\n",
              "        [ 15,   4,  42,   1,  17,  10,   7,  23,  16,  33,   2,  30],\n",
              "        [ 13,   2,  65,   1,  16,  10,   6,  19,  11,  45,   0,  12],\n",
              "        [ 22,   0,  48,   1,  22,  27,   5,  27,   6,  23,   5,  14],\n",
              "        [ 12,   1,  45,   0,  11,   6,   2,   4,  13,  15,   0,  90]]),\n",
              " array([[ 54,  27,   6,   7,  28,   5,  10,  10,   3,  24,  13,  13],\n",
              "        [ 31,  38,  18,   7,  26,   9,   1,   4,  10,  23,   9,  24],\n",
              "        [ 13,   5,  67,   9,  12,   9,   6,  15,   9,  16,  18,  21],\n",
              "        [ 16,  19,  29,   5,  27,   6,   3,  16,   8,  31,  11,  29],\n",
              "        [ 53,  22,   2,  15,  51,   0,  12,   5,   9,   8,   8,  15],\n",
              "        [ 30,  12,  35,  10,  16,   6,   3,  11,   8,  25,  29,  15],\n",
              "        [ 25,  12,  19,   9,  32,   7,  10,  28,   9,  29,  11,   9],\n",
              "        [ 23,   6,  12,  13,  23,   3,   7, 102,   2,   3,   6,   0],\n",
              "        [ 45,  24,  14,  23,  36,   0,   3,   7,   4,  16,  11,  17],\n",
              "        [ 37,  16,  31,  10,  22,   3,   5,  11,   6,  37,  11,  11],\n",
              "        [ 32,  16,  14,  15,  24,   5,  11,  20,   6,  23,  14,  20],\n",
              "        [ 16,  21,  11,  11,  41,   0,   3,   4,   7,   8,   4,  73]]),\n",
              " array([[20, 38,  1,  7, 28, 25,  5,  5, 35, 15, 13,  8],\n",
              "        [22, 46,  3,  8, 21, 13,  6,  9, 39, 11,  5, 17],\n",
              "        [24, 49,  4,  3, 11, 41,  9,  9, 35,  4,  8,  3],\n",
              "        [29, 46,  3,  2, 12, 31,  4,  6, 51,  5,  6,  5],\n",
              "        [21, 16,  2, 22, 24, 18,  8,  4, 41, 33,  3,  8],\n",
              "        [24, 49,  1,  4, 12, 27,  4, 12, 35, 13, 16,  3],\n",
              "        [21, 32,  3, 10, 12, 34,  6, 13, 44,  8, 10,  7],\n",
              "        [27,  9,  1, 38, 27, 13,  3, 21, 39, 18,  2,  2],\n",
              "        [16, 24,  1, 10, 25, 19,  8,  7, 50, 21,  6, 13],\n",
              "        [16, 35,  4,  8, 19, 29,  6,  8, 45, 15, 10,  5],\n",
              "        [26, 27,  2,  7, 14, 32,  4,  8, 44, 23,  6,  7],\n",
              "        [12, 28,  1, 15, 25, 16,  8,  3, 44,  7,  3, 37]]),\n",
              " array([[30, 10, 21, 22, 58, 19,  6,  6,  4,  4, 18,  2],\n",
              "        [26, 30, 30, 18, 47,  7,  2,  6, 14,  8, 10,  2],\n",
              "        [20, 23, 65, 15, 20, 24,  0, 15,  7,  5,  6,  0],\n",
              "        [25, 26, 40, 16, 40, 20,  5, 13,  6,  5,  2,  2],\n",
              "        [22, 23, 30, 12, 65,  8,  3,  6,  9,  9, 11,  2],\n",
              "        [21,  9, 34, 25, 40, 31,  4, 16,  5,  5,  9,  1],\n",
              "        [14,  7, 49, 19, 41, 12, 12, 22,  6,  3, 15,  0],\n",
              "        [ 5,  3, 30, 11, 56,  6,  7, 44,  4, 28,  6,  0],\n",
              "        [11, 14, 48, 10, 53,  5,  1,  6, 15, 20, 14,  3],\n",
              "        [19, 13, 33, 26, 40, 17,  2, 17, 11, 12,  8,  2],\n",
              "        [20, 14, 26, 16, 45, 21, 11, 10, 11,  8, 17,  1],\n",
              "        [12, 21, 51, 24, 31,  4,  0,  2, 10,  8,  4, 32]]),\n",
              " array([[17, 12,  7, 38,  7, 38,  9, 19, 27,  8,  3, 15],\n",
              "        [ 9, 38, 12, 31,  9, 29,  2, 16, 29,  6,  4, 15],\n",
              "        [ 7, 29, 30, 23,  4, 46,  4, 30, 13,  7,  4,  3],\n",
              "        [ 7, 26, 11, 34,  4, 33,  5, 44, 14, 10,  5,  7],\n",
              "        [ 3,  8,  7, 58,  7, 34, 11, 14, 37,  1,  9, 11],\n",
              "        [17, 11, 12, 21,  7, 52,  7, 35, 20,  9,  3,  6],\n",
              "        [10,  8,  6, 34,  4, 42, 13, 46, 22,  7,  4,  4],\n",
              "        [ 0,  0,  6, 64,  3, 14, 12, 81, 10,  2,  1,  7],\n",
              "        [ 5, 20, 12, 60, 13, 27,  9, 13, 20,  7,  4, 10],\n",
              "        [12, 20, 10, 36,  8, 33,  3, 27, 23, 11,  6, 11],\n",
              "        [ 9,  8, 15, 38,  5, 43,  7, 37, 16, 10,  5,  7],\n",
              "        [ 5, 18,  6, 35,  7, 13,  3, 15, 20,  1,  3, 73]])]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cm_5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lE_OGxeDNtno"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entrenamiento número 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_26', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 371ms/step - accuracy: 0.0817 - loss: 1.1235 - val_accuracy: 0.0878 - val_loss: 1.0548\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 332ms/step - accuracy: 0.0807 - loss: 1.0505 - val_accuracy: 0.0822 - val_loss: 1.0400\n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 304ms/step - accuracy: 0.0847 - loss: 1.0378 - val_accuracy: 0.0833 - val_loss: 1.0352\n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 305ms/step - accuracy: 0.0879 - loss: 1.0319 - val_accuracy: 0.0833 - val_loss: 1.0324\n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 308ms/step - accuracy: 0.0864 - loss: 1.0287 - val_accuracy: 0.0844 - val_loss: 1.0257\n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 318ms/step - accuracy: 0.0861 - loss: 1.0269 - val_accuracy: 0.0850 - val_loss: 1.0249\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 314ms/step - accuracy: 0.0832 - loss: 1.0268 - val_accuracy: 0.0878 - val_loss: 1.0234\n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - accuracy: 0.0871 - loss: 1.0253 - val_accuracy: 0.0872 - val_loss: 1.0246\n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 306ms/step - accuracy: 0.0941 - loss: 1.0237 - val_accuracy: 0.0839 - val_loss: 1.0252\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 307ms/step - accuracy: 0.0837 - loss: 1.0222 - val_accuracy: 0.0833 - val_loss: 1.0225\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 316ms/step - accuracy: 0.0872 - loss: 1.0212 - val_accuracy: 0.0839 - val_loss: 1.0210\n",
            "Epoch 12/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 321ms/step - accuracy: 0.0882 - loss: 1.0195 - val_accuracy: 0.0783 - val_loss: 1.0198\n",
            "Epoch 13/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 318ms/step - accuracy: 0.0848 - loss: 1.0195 - val_accuracy: 0.0806 - val_loss: 1.0188\n",
            "Epoch 14/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 308ms/step - accuracy: 0.0883 - loss: 1.0193 - val_accuracy: 0.0833 - val_loss: 1.0195\n",
            "Epoch 15/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 309ms/step - accuracy: 0.0800 - loss: 1.0193 - val_accuracy: 0.0833 - val_loss: 1.0190\n",
            "Epoch 16/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.0859 - loss: 1.0191 - val_accuracy: 0.0833 - val_loss: 1.0181\n",
            "Epoch 17/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 311ms/step - accuracy: 0.0885 - loss: 1.0183 - val_accuracy: 0.0833 - val_loss: 1.0179\n",
            "Epoch 18/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 330ms/step - accuracy: 0.0884 - loss: 1.0181 - val_accuracy: 0.0833 - val_loss: 1.0175\n",
            "Epoch 19/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 308ms/step - accuracy: 0.0835 - loss: 1.0172 - val_accuracy: 0.0839 - val_loss: 1.0181\n",
            "Epoch 20/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.0843 - loss: 1.0162 - val_accuracy: 0.0928 - val_loss: 1.0164\n",
            "Epoch 21/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 309ms/step - accuracy: 0.0902 - loss: 1.0155 - val_accuracy: 0.0822 - val_loss: 1.0153\n",
            "Epoch 22/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 302ms/step - accuracy: 0.0880 - loss: 1.0146 - val_accuracy: 0.1144 - val_loss: 1.0123\n",
            "Epoch 23/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 317ms/step - accuracy: 0.0969 - loss: 1.0131 - val_accuracy: 0.0828 - val_loss: 1.0121\n",
            "Epoch 24/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 331ms/step - accuracy: 0.0850 - loss: 1.0125 - val_accuracy: 0.0856 - val_loss: 1.0111\n",
            "Epoch 25/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 320ms/step - accuracy: 0.0946 - loss: 1.0108 - val_accuracy: 0.1006 - val_loss: 1.0088\n",
            "Epoch 26/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 305ms/step - accuracy: 0.0941 - loss: 1.0098 - val_accuracy: 0.0911 - val_loss: 1.0094\n",
            "Epoch 27/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 306ms/step - accuracy: 0.0996 - loss: 1.0098 - val_accuracy: 0.1139 - val_loss: 1.0091\n",
            "Epoch 28/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 306ms/step - accuracy: 0.0997 - loss: 1.0097 - val_accuracy: 0.1322 - val_loss: 1.0090\n",
            "Epoch 29/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 326ms/step - accuracy: 0.1017 - loss: 1.0095 - val_accuracy: 0.0833 - val_loss: 1.0116\n",
            "Epoch 30/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 311ms/step - accuracy: 0.0951 - loss: 1.0099 - val_accuracy: 0.0833 - val_loss: 1.0096\n",
            "Epoch 30: early stopping\n",
            "Restoring model weights from the end of the best epoch: 25.\n",
            "\n",
            "Entrenamiento número 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_27', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 327ms/step - accuracy: 0.0851 - loss: 1.1537 - val_accuracy: 0.0950 - val_loss: 1.0525\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 297ms/step - accuracy: 0.0846 - loss: 1.0494 - val_accuracy: 0.0833 - val_loss: 1.0427\n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 296ms/step - accuracy: 0.0796 - loss: 1.0371 - val_accuracy: 0.0833 - val_loss: 1.0336\n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 316ms/step - accuracy: 0.0828 - loss: 1.0327 - val_accuracy: 0.0844 - val_loss: 1.0343\n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 321ms/step - accuracy: 0.0827 - loss: 1.0306 - val_accuracy: 0.0972 - val_loss: 1.0283\n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - accuracy: 0.0835 - loss: 1.0298 - val_accuracy: 0.0850 - val_loss: 1.0250\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 301ms/step - accuracy: 0.0783 - loss: 1.0275 - val_accuracy: 0.0833 - val_loss: 1.0254\n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.0872 - loss: 1.0225 - val_accuracy: 0.0833 - val_loss: 1.0267\n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 332ms/step - accuracy: 0.0781 - loss: 1.0230 - val_accuracy: 0.0833 - val_loss: 1.0192\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 316ms/step - accuracy: 0.0923 - loss: 1.0208 - val_accuracy: 0.0928 - val_loss: 1.0200\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - accuracy: 0.0898 - loss: 1.0210 - val_accuracy: 0.0833 - val_loss: 1.0219\n",
            "Epoch 12/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 318ms/step - accuracy: 0.0831 - loss: 1.0212 - val_accuracy: 0.0839 - val_loss: 1.0200\n",
            "Epoch 13/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 316ms/step - accuracy: 0.0828 - loss: 1.0211 - val_accuracy: 0.0833 - val_loss: 1.0206\n",
            "Epoch 14/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 312ms/step - accuracy: 0.0842 - loss: 1.0203 - val_accuracy: 0.0833 - val_loss: 1.0202\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\n",
            "Entrenamiento número 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_28', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 429ms/step - accuracy: 0.0843 - loss: 1.1022 - val_accuracy: 0.0850 - val_loss: 1.0521\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - accuracy: 0.0835 - loss: 1.0484 - val_accuracy: 0.0817 - val_loss: 1.0420\n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - accuracy: 0.0886 - loss: 1.0396 - val_accuracy: 0.0822 - val_loss: 1.0317\n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 320ms/step - accuracy: 0.0764 - loss: 1.0339 - val_accuracy: 0.0917 - val_loss: 1.0302\n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 316ms/step - accuracy: 0.0883 - loss: 1.0260 - val_accuracy: 0.0961 - val_loss: 1.0158\n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 312ms/step - accuracy: 0.0942 - loss: 1.0138 - val_accuracy: 0.0833 - val_loss: 1.0114\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 307ms/step - accuracy: 0.0922 - loss: 1.0113 - val_accuracy: 0.1017 - val_loss: 1.0094\n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 307ms/step - accuracy: 0.0946 - loss: 1.0096 - val_accuracy: 0.1311 - val_loss: 1.0068\n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 346ms/step - accuracy: 0.0979 - loss: 1.0058 - val_accuracy: 0.0889 - val_loss: 1.0037\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - accuracy: 0.1008 - loss: 1.0028 - val_accuracy: 0.0950 - val_loss: 1.0020\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 305ms/step - accuracy: 0.1086 - loss: 1.0023 - val_accuracy: 0.0917 - val_loss: 1.0034\n",
            "Epoch 12/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 309ms/step - accuracy: 0.1043 - loss: 1.0027 - val_accuracy: 0.0894 - val_loss: 1.0032\n",
            "Epoch 13/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - accuracy: 0.1016 - loss: 1.0029 - val_accuracy: 0.0944 - val_loss: 1.0026\n",
            "Epoch 14/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 315ms/step - accuracy: 0.1056 - loss: 1.0026 - val_accuracy: 0.0867 - val_loss: 1.0030\n",
            "Epoch 15/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 314ms/step - accuracy: 0.0953 - loss: 1.0034 - val_accuracy: 0.0833 - val_loss: 1.0040\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\n",
            "Entrenamiento número 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_29', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 337ms/step - accuracy: 0.0858 - loss: 1.1588 - val_accuracy: 0.0833 - val_loss: 1.0457\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 307ms/step - accuracy: 0.0776 - loss: 1.0386 - val_accuracy: 0.0833 - val_loss: 1.0321\n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 314ms/step - accuracy: 0.0866 - loss: 1.0283 - val_accuracy: 0.0789 - val_loss: 1.0266\n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 307ms/step - accuracy: 0.0816 - loss: 1.0267 - val_accuracy: 0.0828 - val_loss: 1.0231\n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - accuracy: 0.0913 - loss: 1.0239 - val_accuracy: 0.0806 - val_loss: 1.0191\n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 307ms/step - accuracy: 0.0855 - loss: 1.0194 - val_accuracy: 0.0878 - val_loss: 1.0196\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - accuracy: 0.0867 - loss: 1.0196 - val_accuracy: 0.0878 - val_loss: 1.0188\n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 312ms/step - accuracy: 0.0863 - loss: 1.0195 - val_accuracy: 0.0839 - val_loss: 1.0210\n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 304ms/step - accuracy: 0.0836 - loss: 1.0198 - val_accuracy: 0.1044 - val_loss: 1.0184\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.0926 - loss: 1.0192 - val_accuracy: 0.0856 - val_loss: 1.0184\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 307ms/step - accuracy: 0.0932 - loss: 1.0193 - val_accuracy: 0.0994 - val_loss: 1.0177\n",
            "Epoch 12/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 306ms/step - accuracy: 0.0897 - loss: 1.0187 - val_accuracy: 0.0833 - val_loss: 1.0199\n",
            "Epoch 13/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 306ms/step - accuracy: 0.0892 - loss: 1.0190 - val_accuracy: 0.0850 - val_loss: 1.0181\n",
            "Epoch 14/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 314ms/step - accuracy: 0.0946 - loss: 1.0192 - val_accuracy: 0.1033 - val_loss: 1.0180\n",
            "Epoch 15/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.0851 - loss: 1.0191 - val_accuracy: 0.0850 - val_loss: 1.0181\n",
            "Epoch 16/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 302ms/step - accuracy: 0.0886 - loss: 1.0189 - val_accuracy: 0.0861 - val_loss: 1.0188\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\n",
            "Entrenamiento número 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'mlp_30', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 325ms/step - accuracy: 0.0835 - loss: 1.0865 - val_accuracy: 0.0861 - val_loss: 1.0230\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 308ms/step - accuracy: 0.0831 - loss: 1.0192 - val_accuracy: 0.0828 - val_loss: 1.0150\n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 315ms/step - accuracy: 0.0847 - loss: 1.0157 - val_accuracy: 0.0844 - val_loss: 1.0135\n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.0867 - loss: 1.0148 - val_accuracy: 0.0922 - val_loss: 1.0145\n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 297ms/step - accuracy: 0.0837 - loss: 1.0146 - val_accuracy: 0.0822 - val_loss: 1.0124\n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 299ms/step - accuracy: 0.0840 - loss: 1.0149 - val_accuracy: 0.0967 - val_loss: 1.0115\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.0871 - loss: 1.0150 - val_accuracy: 0.0956 - val_loss: 1.0153\n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 318ms/step - accuracy: 0.0892 - loss: 1.0147 - val_accuracy: 0.0861 - val_loss: 1.0130\n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 325ms/step - accuracy: 0.0938 - loss: 1.0144 - val_accuracy: 0.0950 - val_loss: 1.0160\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 318ms/step - accuracy: 0.0887 - loss: 1.0145 - val_accuracy: 0.0944 - val_loss: 1.0132\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 318ms/step - accuracy: 0.0882 - loss: 1.0146 - val_accuracy: 0.0822 - val_loss: 1.0163\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n"
          ]
        }
      ],
      "source": [
        "# Modelo 3 - QuickDraw-Animals\n",
        "# Detalles:\n",
        "# Activacion: sigmoid\n",
        "# Perdida: kullback_leibler_divergence\n",
        "# Capas: 2\n",
        "# Epocas: 10\n",
        "# Batch size: 1000\n",
        "\n",
        "acc_total_6, acc_clase_6, cm_6 = experiment(\n",
        "        train_images_animals,\n",
        "        train_labels_animals,\n",
        "        val_images_animals,\n",
        "        val_labels_animals,\n",
        "        test_images_animals,\n",
        "        test_labels_animals,\n",
        "        layers_size=[512, 256, 128, 64],\n",
        "        n_classes=12,\n",
        "        activation='tanh',\n",
        "        loss_fn='categorical_hinge',\n",
        "        class_names=clases,\n",
        "        epochs=100,\n",
        "        batch_size=512,\n",
        "        n_experiments=5\n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
